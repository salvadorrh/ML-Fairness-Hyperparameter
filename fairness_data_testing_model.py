# -*- coding: utf-8 -*-
"""Fairness Data Testing Model

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mr5qh11CbQbRWNwPkDTOvd2mDOj17F56

# Fairness Data Testing

**What do we want to achieve?**
> We want to figure out if it's possible for a way that we can create a function, a way to predict the level of fairness from a specific configuration of hyperparameters of ML algorithms provided from popular ML libraries like scikit-learn.

**Why is it important?**

> Fairness has been a very important subject regarding Machine Learning. There has always been the major goal to achieve the best accuracy possible, but this can lead to a single metric that can be misleading. Discrimination on certain categories of the data can arise.

> From different features we predict the desired output, there exist cases in which some of this feature may represent something very sensitive like gender or race. This will be our protected attributes. Maybe we have achieved the best accuracy possible with our ML model, but there will be problems if by maintaing the same features and only chaning the race or gender the output is different. This may lead to biases against some gender or race. To measure the group fairness we can calculate the AOD (Average Odd Difference) which is the average of differences between the true positive rates and the false positive rates of two protected groups.

*What if we can provide a way to know the AOD by knowing the hyperparameter configuration of a ML algorithm?*


*   Time on running the experiments will be saved. In knowing AOD for a specific set of hyperparameters you don't need to run an experiment with the hyperparameters that are going to be used.
*   Easier way to calculate AOD leads to easier incorporation and awareness of the importance of group fairness in our results.


**How are we approaching this questions?**
> We have gathered a good amount of data from numerous runs of experimenting with different configurations of hyperparameters to achieve the best combination of good accuracy and the best fairness possible. This runs consists of the use of different ML-algorithms, different set of hyperparameters, different protected attributes on different datasets.
> With this data we will figure out if we can use Machine Learning to predict the AOD from any hyperparameter configuration of certain ML algorithms (currently we will be using 5 different ML algorithms which are provided by the popular ML library scikit-learn).

**Follow-up and Research Questions**

*   What is the best ML algorithm to calculate the AOD from a set of hyperparameters, protected attribute and dataset?
*   Can our ML models achieve the same performance across different protected attributes and datasets? Or is a model dependent to a specific dataset and/or protected attribute?

## Set Up and Data Recollection

### Load Libraries

Let's start by loading the libraries that we will be using. Including ML libraries and plotting tools that will help us in this project.
"""

# General libraries
import pandas as pd
import numpy as np
from google.colab import files
import io # to read bytes type into pandas dataframe
from sklearn.preprocessing import OneHotEncoder
from matplotlib import pyplot as plt
from sklearn.model_selection import train_test_split
import math
from sklearn.utils import shuffle
from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_absolute_error
from sklearn.metrics import r2_score
import time

# Neural Network
import tensorflow as tf

# Other ML algorithms
import sklearn
from sklearn import svm
from sklearn.linear_model import LinearRegression
from sklearn.linear_model import RANSACRegressor
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.ensemble import GradientBoostingRegressor
import xgboost

print('The tf version is {}.'.format(tf.__version__))
print('The scikit-learn version is {}.'.format(sklearn.__version__))
print('XGBoost version is {}.'.format(xgboost.__version__))

!df -h

!cat /proc/cpuinfo

"""### Download Datasets

The data in the CSV files that we have are the result of experimenting with different hyperparameters on ML algorithms provided by libraries like Scikit-Learn. Numerous runs with 5 Machine Learning algorithms and different datasets.

This 5 algorithms are:

- Decision Tree Classifier
- Discriminant Analysis
- Logistic Regression
- Support Vector Machine
- Tree Regressor

Datasets:
-
"""

# Upload csv files that will be used for learning
uploaded = files.upload()

# Name of files being used
# Decision Tree Classifier
dtc_bank_age = 'Decision_Tree_Classifier_bank_age_mutation_res.csv'
dtc_census_gender = 'Decision_Tree_Classifier_census_gender_mutation_res.csv'
dtc_census_race = 'Decision_Tree_Classifier_census_race_mutation_res.csv'
dtc_compas_gender = 'Decision_Tree_Classifier_compas_gender_coverage_1628116423_res.csv'
dtc_compas_race = 'Decision_Tree_Classifier_compas_race_coverage_1628116493_res.csv'
dtc_credit_gender = 'Decision_Tree_Classifier_credit_gender_mutation_res.csv'

# Discriminant Analysis
da_bank_age = 'Discriminant_Analysis_bank_age_mutation_res.csv'
da_census_gender = 'Discriminant_Analysis_census_gender_mutation_res.csv'
da_census_race = 'Discriminant_Analysis_census_race_mutation_res.csv'
da_compas_gender = 'Discriminant_Analysis_compas_gender_random_1628114206_res.csv'
da_compas_race = 'Discriminant_Analysis_compas_race_coverage_1628114343_res.csv'
da_credit_gender = 'Discriminant_Analysis_credit_gender_mutation_res.csv'

# Logistic Regression
lr_bank_age = 'LogisticRegression_bank_age_mutation_res.csv'
lr_census_gender = 'LogisticRegression_census_gender_mutation_res.csv'
lr_census_race = 'LogisticRegression_census_race_mutation_res.csv'
lr_compas_gender = 'LogisticRegression_compas_gender_mutation_1628116237_res.csv'
lr_compas_race = 'LogisticRegression_compas_race_mutation_1628116303_res.csv'
lr_credit_gender = 'LogisticRegression_credit_gender_mutation_res.csv'

# Support Vector Machine
svm_bank_age = 'SVM_bank_age_mutation_1628264971_res.csv'
svm_census_gender = 'SVM_census_gender_mutation_1628264300_res.csv'
svm_census_race = 'SVM_census_race_mutation_1628264315_res.csv'
svm_compas_gender = 'SVM_compas_gender_mutation_1628265230_res.csv'
svm_compas_race = 'SVM_compas_race_mutation_1628265601_res.csv'
svm_credit_gender = 'SVM_credit_gender_random_1628264669_res.csv'

# Tree Regressor
tr_bank_age = 'TreeRegressor_bank_age_mutation_res.csv'
tr_census_gender = 'TreeRegressor_census_gender_mutation_res.csv'
tr_census_race = 'TreeRegressor_census_race_mutation_res.csv'
tr_compas_gender = 'TreeRegressor_compas_gender_coverage_1628114251_res.csv'
tr_compas_race = 'TreeRegressor_compas_race_mutation_1628114319_res.csv'
tr_credit_gender = 'TreeRegressor_credit_gender_mutation_res.csv'

# New census data
# Logistic Regression
lr_census_2014_sex = 'LRCENSUS_2014_sex.csv'
lr_census_2015_sex = 'LRCENSUS_2015_sex.csv'
lr_census_2018_sex = 'LRCENSUS_2018_sex.csv'
lr_census_2014_race = 'LRCENSUS_2014_race.csv'
lr_census_2015_race = 'LRCENSUS_2015_race.csv'
lr_census_2018_race = 'LRCENSUS_2018_race.csv'

# Decision Tree Classifier
dtc_census_2014_sex = 'DTCENSUS_2014_sex.csv'
dtc_census_2015_sex = 'DTCENSUS_2015_sex.csv'
dtc_census_2018_sex = 'DTCENSUS_2018_sex.csv'
dtc_census_2014_race = 'DTCENSUS_2014_race.csv'
dtc_census_2015_race = 'DTCENSUS_2015_race.csv'
dtc_census_2018_race = 'DTCENSUS_2018_race.csv'

# Support Vector Machine
svm_census_2014_sex = 'SVMCENSUS_2014_sex.csv'
svm_census_2015_sex = 'SVMCENSUS_2015_sex.csv'
svm_census_2018_sex = 'SVMCENSUS_2018_sex.csv'
svm_census_2014_race = 'SVMCENSUS_2014_race.csv'
svm_census_2015_race = 'SVMCENSUS_2015_race.csv'
svm_census_2018_race = 'SVMCENSUS_2018_race.csv'

# Tree Regressor
tr_census_2014_sex = 'TRCENSUS_2014_sex.csv'
tr_census_2015_sex = 'TRCENSUS_2015_sex.csv'
tr_census_2018_sex = 'TRCENSUS_2018_sex.csv'
tr_census_2014_race = 'TRCENSUS_2014_race.csv'
tr_census_2015_race = 'TRCENSUS_2015_race.csv'
tr_census_2018_race = 'TRCENSUS_2018_race.csv'

# Discriminant Analysis
da_census_2014_sex = 'DACENSUS_2014_sex.csv'
da_census_2015_sex = 'DACENSUS_2015_sex.csv'
da_census_2018_sex = 'DACENSUS_2018_sex.csv'
da_census_2014_race = 'DACENSUS_2014_race.csv'
da_census_2015_race = 'DACENSUS_2015_race.csv'
da_census_2018_race = 'DACENSUS_2018_race.csv'

# Census across states 2014
da_census_2014_sex_CA = 'DACENSUS_2014_sex_CA.csv'
da_census_2014_race_CA = 'DACENSUS_2014_race_CA.csv'

"""### Feature Engineering/ Prepare data for Machine Learning

As previously mentioned the data that we have consists of results coming from 5 different type of ML algorithms.
"""

"""
  Transforms downloaded data from a bytes format to Numpy arrays.
  Input: Name of files. Must be results from Decision Tree Classifier experiments.
  Output: X and Y numpy arrays
"""
def get_data_dtc(files, split=False, random_state=2001, y_col='AOD'):
  # One hot encoder that will represent categorical features
  ohe = OneHotEncoder()
  # Transforms data into a Pandas format, for easier manipulation
  training_data = pd.read_csv(io.BytesIO(uploaded[files[0]]))
  for i in range(1, len(files)-1):
    training_data = pd.concat([training_data, pd.read_csv(io.BytesIO(uploaded[files[i]]))])
  training_data = pd.concat([training_data, pd.read_csv(io.BytesIO(uploaded[files[len(files)-1]]))])

  # Columns we care about from the original dataset
  x_cols = ['max_depth', 'min_samples_split',
            'min_samples_leaf', 'min_weight_fraction_leaf']
  y_col = [y_col] # Selecting fairness notion. AOD, or EOD

  X_data = training_data[x_cols]
  X_data = X_data.replace({'max_depth': {np.nan:0}}) # Replaces nan values in max_depth column

  # Transforms data into X and Y numpys
  X_data = X_data.to_numpy()
  Y = training_data[y_col].to_numpy()

  # Will add columns that will be transformed into a One-Hot-Encoding
  X = training_data[['criterion', 'splitter', 'max_features']]
  X_ohe = ohe.fit_transform(X).toarray()

  # Append these two datasets of the X data
  X = np.hstack((X_data, X_ohe))

  # Stack numpy arrays vertically
  XY = np.column_stack((X,Y))
  num_feas = XY.shape[1]-1

  XY = np.unique(XY, axis=0)
  X = XY[:,0:num_feas] # Features
  Y = XY[:,num_feas] # Output

  if split == False:
    return X, Y
  else:
    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=random_state)
    return X_train, X_test, y_train, y_test

"""
  Transforms downloaded data from a bytes format to Numpy arrays.
  Input: Name of files. Must be results from Discriminant Analysis experiments.
  Output: X and Y numpy arrays
"""
def get_data_da(files,split=False, random_state=2001, y_col='AOD'):
  # One hot encoder that will represent categorical features
  ohe = OneHotEncoder()
  # Transforms data into a Pandas format, for easier manipulation
  #training_data = pd.concat(pd.read_csv(io.BytesIO(uploaded[file])) for file in files)
  training_data = pd.read_csv(io.BytesIO(uploaded[files[0]]))
  for i in range(1, len(files)-1):
    training_data = pd.concat([training_data, pd.read_csv(io.BytesIO(uploaded[files[i]]))])
  num_rows = training_data.shape[0]
  training_data = pd.concat([training_data, pd.read_csv(io.BytesIO(uploaded[files[len(files)-1]]))])

  # Columns we care about from the original dataset
  x_cols = ['tol', 'reg_param']
  y_col = [y_col] # Selecting fairness notion. AOD, or EOD

  X_data = training_data[x_cols]

  # Transforms data into X and Y numpys
  X_data = X_data.to_numpy()
  Y = training_data[y_col].to_numpy()

  # Will add columns that will be transformed into a One-Hot-Encoding
  X = training_data[['linear(0)_quadratic(1)', 'solver_Linear',
                     'Shrinkage_Linear', 'component', 'store_covariance',
                     'type_dataset']]
  X_ohe = ohe.fit_transform(X).toarray()

  # Append these two datasets of the X data
  X = np.hstack((X_data, X_ohe))

  # Stack numpy arrays vertically
  XY = np.column_stack((X,Y))
  num_feas = XY.shape[1]-1

  print('XY shape before: ', XY.shape)
  XY = np.unique(XY, axis=0)
  print('XY shape after: ', XY.shape)
  X = XY[:,0:num_feas] # Features
  Y = XY[:,num_feas] # Output

  if split == False:
    return X, Y
  else:
    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=random_state)
    return X_train, X_test, y_train, y_test

"""
  Transforms downloaded data from a bytes format to Numpy arrays.
  Input: Name of files. Must be results from Logistic Regression experiments.
  Output: X and Y numpy arrays
"""
def get_data_lr(files, split=False, random_state=2001, y_col='AOD'):
  # One hot encoder that will represent categorical features
  ohe = OneHotEncoder()
  # Transforms data into a Pandas format, for easier manipulation
  # training_data = pd.concat(pd.read_csv(io.BytesIO(uploaded[file])) for file in files)
  training_data = pd.read_csv(io.BytesIO(uploaded[files[0]]))
  for i in range(1, len(files)-1):
    training_data = pd.concat([training_data, pd.read_csv(io.BytesIO(uploaded[files[i]]))])
  num_rows = training_data.shape[0]
  training_data = pd.concat([training_data, pd.read_csv(io.BytesIO(uploaded[files[len(files)-1]]))])

  # Columns we care about from the original dataset
  x_cols = ['tol', 'C', 'intercept_scaling', 'max_iteration', 'l1_ratio']
  y_col = [y_col] # Selecting fairness notion. AOD, or EOD

  X_data = training_data[x_cols]
  X_data = X_data.replace({'l1_ratio': {np.nan:0}}) # Replaces nan values in l1_ratio column

  # Transforms data into X and Y numpys
  X_data = X_data.to_numpy()
  Y = training_data[y_col].to_numpy()

  # Will add columns that will be transformed into a One-Hot-Encoding
  X = training_data[['solver', 'penalty', 'dual', 'fit_intercept', 'multi_class']]
  X_ohe = ohe.fit_transform(X).toarray()

  # Append these two datasets of the X data
  X = np.hstack((X_data, X_ohe))

  # Stack numpy arrays vertically
  XY = np.column_stack((X,Y))
  num_feas = XY.shape[1]-1

  XY = np.unique(XY, axis=0)
  X = XY[:,0:num_feas] # Features
  Y = XY[:,num_feas] # Output

  if split == False:
    return X, Y
  else:
    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=random_state)
    return X_train, X_test, y_train, y_test

"""
  Transforms downloaded data from a bytes format to Numpy arrays.
  Input: Name of files. Must be results from Support Vector Machine experiments.
  Output: X and Y numpy arrays
"""
def get_data_svm(files, split=False, random_state=2001,y_col='AOD'):
  # One hot encoder that will represent categorical features
  ohe = OneHotEncoder()
  # Transforms data into a Pandas format, for easier manipulation
  #training_data = pd.concat(pd.read_csv(io.BytesIO(uploaded[file])) for file in files)
  training_data = pd.read_csv(io.BytesIO(uploaded[files[0]]))
  for i in range(1, len(files)-1):
    training_data = pd.concat([training_data, pd.read_csv(io.BytesIO(uploaded[files[i]]))])
  num_rows = training_data.shape[0]
  training_data = pd.concat([training_data, pd.read_csv(io.BytesIO(uploaded[files[len(files)-1]]))])

  training_data = training_data[training_data['AOD'].notna()]
  # Columns we care about from the original dataset
  x_cols = ['tol', 'C', 'intercept_scaling']
  y_col = [y_col] # Selecting fairness notion. AOD, or EOD
  X_data = training_data[x_cols]

  # Transforms data into X and Y numpys
  X_data = X_data.to_numpy()
  Y = training_data[y_col].to_numpy()

  # Will add columns that will be transformed into a One-Hot-Encoding
  # Not using multi_Class (all are ovr)
  X = training_data[['penalty', 'loss', 'degree', 'fit_intercept',
                     'class_weight']]
  X_ohe = ohe.fit_transform(X).toarray()

  # Append these two datasets of the X data
  X = np.hstack((X_data, X_ohe))

  # Stack numpy arrays vertically
  XY = np.column_stack((X,Y))
  num_feas = XY.shape[1]-1

  XY = np.unique(XY, axis=0)
  X = XY[:,0:num_feas] # Features
  Y = XY[:,num_feas] # Output

  if split == False:
    return X, Y
  else:
    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=random_state)
    return X_train, X_test, y_train, y_test

"""
  Transforms downloaded data from a bytes format to Numpy arrays.
  Input: Name of files. Must be results from Tree Regressor experiments.
  Output: X and Y numpy arrays
"""
def get_data_tr(files, split=False, random_state=2001,y_col='AOD'):
  # One hot encoder that will represent categorical features
  ohe = OneHotEncoder()
  # Transforms data into a Pandas format, for easier manipulation
  #training_data = pd.concat(pd.read_csv(io.BytesIO(uploaded[file])) for file in files)

  training_data = pd.read_csv(io.BytesIO(uploaded[files[0]]))
  for i in range(1, len(files)-1):
    training_data = pd.concat([training_data, pd.read_csv(io.BytesIO(uploaded[files[i]]))])
  num_rows = training_data.shape[0]
  training_data = pd.concat([training_data, pd.read_csv(io.BytesIO(uploaded[files[len(files)-1]]))])

  training_data = training_data[training_data['AOD'].notna()]
  # Columns we care about from the original dataset
  x_cols = ['max_depth', 'min_samples_split', 'min_samples_leaf',
            'min_weight_fraction_leaf', 'n_estimators', 'max_samples']
  y_col = [y_col] # Selecting fairness notion. AOD, or EOD
  X_data = training_data[x_cols]

  X_data = X_data.replace({'max_depth': {np.nan:0}}) # Replaces nan values in max_depth column
  #X_data = X_data.replace({'min_samples_split': {np.nan:0}})
  X_data = X_data.replace({'max_samples': {np.nan:0}})

  # Transforms data into X and Y numpys
  X_data = X_data.to_numpy()

  Y = training_data[y_col].to_numpy()

  # Will add columns that will be transformed into a One-Hot-Encoding
  # Not using max_leaf_nodes, min_impurity_decrease, bootstrap, ccp_alpha
  X = training_data[['criterion', 'max_features', 'oob_score', 'warm_start']]
  X_ohe = ohe.fit_transform(X).toarray()

  # Append these two datasets of the X data
  X = np.hstack((X_data, X_ohe))

  # Stack numpy arrays vertically
  XY = np.column_stack((X,Y))
  num_feas = XY.shape[1]-1

  XY = np.unique(XY, axis=0)
  X = XY[:,0:num_feas] # Features
  Y = XY[:,num_feas] # Output

  if split == False:
    return X, Y
  else:
    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=random_state)
    return X_train, X_test, y_train, y_test

X, Y = get_data_da([da_census_gender])
print('Dataset: ', da_census_gender)
print(X.shape)
print(Y.shape)

X, Y = get_data_lr([lr_census_gender])
print('Dataset: ', lr_census_gender)
print(X.shape)
print(Y.shape)

X, Y = get_data_svm([svm_census_gender])
print('Dataset: ', svm_census_gender)
print(X.shape)
print(Y.shape)

X, Y = get_data_tr([tr_census_gender])
print('Dataset: ', tr_census_gender)
print(X.shape)
print(Y.shape)

X, Y = get_data_dtc([dtc_compas_gender],y_col='TPR')
print('Dataset: ', dtc_compas_gender)
print(X.shape)
print(Y.shape)

X_1, Y_1 = get_data_dtc([dtc_compas_gender])

"""Let's see at how our data looks."""

print('X.shape: ', X.shape)
print('Y.shape: ', Y.shape)
print('Example of data: ')
print(X[0])
print(Y[0])
print('Example of data: ')
print(X[1])
print(Y[1])

"""For these experiments we will use a 80-20 ratio split for training and testing data. 80% of data will be for training and 20% of data will be for testing.

We wil split the data with the train_test_split provided by sklearn.
"""

X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=2001)

X_train_1, X_test_1, y_train_1, y_test_1 = train_test_split(X_1, Y_1, test_size=0.2, random_state=2001)

"""### Data Analysis

Let's see what valuable information we can gather from the data.
"""

# Shape
print('X_train.shape: ', X_train.shape)
print('X_test.shape: ', X_test.shape)
print('y_train.shape: ', y_train.shape)
print('y_test.shape: ', y_test.shape)

# Shape of data 2
print('X_train_1.shape: ', X_train_1.shape)
print('X_test_1.shape: ', X_test_1.shape)
print('y_train_1.shape: ', y_train_1.shape)
print('y_test_1.shape: ', y_test_1.shape)

# Basic statistics of our AOD (Y/output)
print('Maximum AOD value: ', max(Y))
print('Minimum AOD value: ', min(Y))
avg_y = sum(Y)/len(Y)
print('Average AOD value: ', avg_y)

# Basic statistics of our AOD 2 (Y/output)
print('Maximum AOD value: ', max(Y_1))
print('Minimum AOD value: ', min(Y_1))
avg_y_1 = sum(Y_1)/len(Y_1)
print('Average AOD value: ', avg_y_1)

"""### Baseline Model

In order to figure out if our ML models are actually learning something valuable, we can compare them to a basline model. What is a baseline model? It is a first simple attempt to creating a model which will be a reference point for future predictions. The advantages of a baseline model is that we can have a reference point to which we can compare our ML models. If the loss of a ML model is worse than this baseline (or fairly the same loss), then that means that the model is not learning.

To create our baseline model we will compute the average value of the outputs (Y), and that value will be the prediction for all the other values we want to predict. This doesn't require any Machine Learning or any difficult process or algorithm. Is just predicting the same value regardles of the input.

The mean squared error of the predicition against the true values will be our baseline loss. The goal of our ML algorithms is to predict some Y which the loss is less than the baseline loss, if not, then we can say that our ML model is not a very good one.
"""

"""
  Errors formula: Which outputs the absolute error and the relative error.
"""
def errors(mse_data, avg_data):
  rmse_data = math.sqrt(mse_data)
  rel_rmse_data = rmse_data/avg_data
  return rmse_data, rel_rmse_data

"""
  Creates baseline model and calculates average
"""
def baseline_model(y_vector, y_vector_shape):
  avg_y = sum(y_vector)/len(y_vector)
  baseline = np.full(y_vector_shape, avg_y)
  return baseline, avg_y

# Baseline model for first dataset
baseline_preds, avg = baseline_model(y_train, y_test.shape)

# Get loss for the baseline model
mse = mean_squared_error(baseline_preds, y_test)
abs_error, rel_error = errors(mse,avg)
print('mse: ', mse)
print('avg: ', avg)
print('Abs error: ', abs_error)
print('Rel error: ', rel_error)

# Baseline model for second dataset
baseline_preds, avg = baseline_model(y_train_1, y_test_1.shape)

# Get loss for the baseline model
mse = mean_squared_error(baseline_preds, y_test_1)
abs_error, rel_error = errors(mse,avg)
print('mse: ', mse)
print('avg: ', avg)
print('Abs error: ', abs_error)
print('Rel error: ', rel_error)

"""## Neural Network Experimentation

There are different algorithms that can be used to solved a Regression problem like we have at hand in this case.

In this section there will be experimentation with different Machine Learning algorithms to see the different results and what works best within our data.

First let's try a Neural Network and experiment with the size and layers of the neural network.

**Neural Network**



*   First Neural Network created has 4 dense layers with 32 units each.
*   Second Neural Network
"""

# Neural Network model
def create_NN_model(input_dim):
  # Clear session and remove randomness.
  tf.keras.backend.clear_session()
  tf.random.set_seed(0)

  model = tf.keras.Sequential()
  # Input layer
  model.add(tf.keras.layers.Dense(units=256, input_dim = input_dim, kernel_initializer='normal'))
  # Hidden layers
  model.add(tf.keras.layers.Dense(units=128, activation='ReLU'))
  model.add(tf.keras.layers.Dense(units=64, activation='ReLU'))
  model.add(tf.keras.layers.Dense(units=32, activation='ReLU'))
  model.add(tf.keras.layers.Dense(units=16, activation='ReLU'))
  model.add(tf.keras.layers.Dense(units=8, activation='ReLU'))
  model.add(tf.keras.layers.Dense(units=4, activation='ReLU'))
  # Output layer
  model.add(tf.keras.layers.Dense(units=1, activation="linear"))

  model.compile(loss="mean_squared_error",
                optimizer=tf.keras.optimizers.Adam(),
                metrics=["mean_squared_error"])

  return model

# Neural Network model
def create_NN_model_1(input_dim):
  # Clear session and remove randomness.
  tf.keras.backend.clear_session()
  tf.random.set_seed(0)

  model = tf.keras.Sequential()
  # Input layer
  model.add(tf.keras.layers.Dense(units=32, input_dim = input_dim, kernel_initializer='normal'))
  # Hidden layers
  model.add(tf.keras.layers.Dense(units=32, activation='ReLU'))
  model.add(tf.keras.layers.Dense(units=32, activation='ReLU'))
  model.add(tf.keras.layers.Dense(units=32, activation='ReLU'))
  # Output layer
  model.add(tf.keras.layers.Dense(units=1, activation="linear"))

  model.compile(loss="mean_squared_error",
                optimizer=tf.keras.optimizers.Adam(),
                metrics=["mean_squared_error"])

  return model

# Neural Network model. Can customize number of layer and number of units in each layer
def create_NN_model_conf(n_layers=4, n_units=32):
  # Clear session and remove randomness.
  tf.keras.backend.clear_session()
  tf.random.set_seed(0)

  model = tf.keras.Sequential()
  # Input layer
  model.add(tf.keras.layers.Dense(units=n_units, input_dim = 12, kernel_initializer='normal', activation='ReLU'))
  for i in range(n_layers):
    model.add(tf.keras.layers.Dense(units=n_units, activation='ReLU'))

  # Output layer
  model.add(tf.keras.layers.Dense(units=1))

  model.compile(loss="mean_squared_error",
                optimizer='adam',
                metrics=["mean_squared_error"])

  return model

# Plot history function that tracks the loss and validation loss through the different epochs
def plot_history(history):
  plt.ylabel('Loss')
  plt.xlabel('Epoch')
  plt.xticks(range(0, len(history['loss'] + 1)))
  plt.plot(history['loss'], label="training", marker='o')
  plt.plot(history['val_loss'], label="validation", marker='o')
  plt.legend()
  plt.show()

model_1 = create_NN_model()

#callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=20)

history = model_1.fit(
  X_train,
  y_train,
  epochs=10,
  batch_size=32,
  validation_data=(X_test,y_test),
  #callbacks=[callback],
  verbose=1
  )

history = pd.DataFrame(history.history)
plot_history(history)

print(model_1.summary())

model_2 = create_NN_model_conf(n_layers=16,n_units=256)

history = model_2.fit(
  X_train,
  y_train,
  epochs=100,
  batch_size=64,
  validation_data=(X_test,y_test),
  verbose=1
  )

history = pd.DataFrame(history.history)
plot_history(history)

print(model_2.summary())

model_3 = create_NN_model_conf(n_layers=8,n_units=32)

history = model_3.fit(
  X_train_1,
  y_train_1,
  epochs=100,
  batch_size=32,
  validation_data=(X_test_1,y_test_1),
  verbose=1
  )

history = pd.DataFrame(history.history)
plot_history(history)

print(model_3.summary())

"""## ML algorithm experimentation

In this case we require a Regression problem solution. This section will provide some experimentation of different other ML algorithms to see if we can get better results (less loss and validation loss). To more accurately predict the AOD with different ML algorithms.

Some of the algorithms to try are the following:

**Support Vector Machine**

For the first ML algorithm. We can't use a normal SCM classifier, but we can use a SVR, which is a Support Vector Regressor. Note that there are different types of SVR such as:

* SVR: A normal Support Vector Regressor.
* NuSVR
* LinearSVR
"""

# Data num 1
model_svm = svm.SVR(kernel='poly', degree=4, gamma='scale', max_iter=400)

model_svm.fit(X_train, y_train)

y_pred = model_svm.predict(X_test)

# Computer the Mean square error of the results vs prediction
mse = mean_squared_error(y_pred, y_test)
print('mse: ', mse)

# Data num 2
model_svm = svm.SVR(kernel='poly',degree=3, gamma='auto')

model_svm.fit(X_train_1, y_train_1)

y_pred = model_svm.predict(X_test_1)

# Computer the Mean square error of the results vs prediction
mse = mean_squared_error(y_pred, y_test_1)
print('mse: ', mse)

# Data num 1
model_svm = svm.NuSVR(kernel='rbf', gamma='auto', max_iter=50000)

model_svm.fit(X_train, y_train)

y_pred = model_svm.predict(X_test)

# Computer the Mean square error of the results vs prediction
mse = mean_squared_error(y_pred, y_test)
print('mse: ', mse)

# Data num 2
model_svm = svm.NuSVR(kernel='rbf', gamma='auto', max_iter=50000)

model_svm.fit(X_train_1, y_train_1)

y_pred = model_svm.predict(X_test_1)

# Computer the Mean square error of the results vs prediction
mse = mean_squared_error(y_pred, y_test_1)
print('mse: ', mse)

model_svm = svm.LinearSVR(loss='squared_epsilon_insensitive')

model_svm.fit(X_train, y_train)

y_pred = model_svm.predict(X_test)

# Computer the Mean square error of the results vs prediction
mse = mean_squared_error(y_pred, y_test)
print('mse: ', mse)

model_svm = svm.LinearSVR(loss='squared_epsilon_insensitive')

model_svm.fit(X_train_1, y_train_1)

y_pred = model_svm.predict(X_test_1)

# Computer the Mean square error of the results vs prediction
mse = mean_squared_error(y_pred, y_test_1)
print('mse: ', mse)

"""**Linear Regression**

Let's try a simple Linear Regression model.
"""

reg = LinearRegression().fit(X_train, y_train)

y_pred = reg.predict(X_test)
# Computer the Mean square error of the results vs prediction
mse = mean_squared_error(y_pred, y_test)
print('mse: ', mse)

# Data num 2
reg = LinearRegression().fit(X_train_1, y_train_1)

y_pred = reg.predict(X_test_1)
# Computer the Mean square error of the results vs prediction
mse = mean_squared_error(y_pred, y_test_1)
print('mse: ', mse)

"""**RANSAC Regressor**

Now we will try a RANSAC Regressor algorithm.
"""

ransac = RANSACRegressor(LinearRegression(),
		max_trials=20, 		# Number of Iterations
		min_samples=5, 		# Minimum size of the sample
		loss='squared_error', 	# Metrics for loss
		residual_threshold=10 	# Threshold
		).fit(X_train, y_train)

# reg = RANSACRegressor().fit(X_train, y_train)

y_pred = ransac.predict(X_test)
# Computer the Mean square error of the results vs prediction
mse = mean_squared_error(y_pred, y_test)
print('mse: ', mse)

"""**Decision Tree and Random Forest**

Now we can try a type of Decision Tree which are not for classification problems but for regression type of problems.

I will also experiment on the best hyperparameters to place on the Decision Tree Regressor algorithm to get the best results.

Overall a depth of 15 was better in the first dataset. But the results were around 0.0004 MSE loss for the depths of 20, 25, 30, 35, 40. On the next dataset a depth of 20 was better.
"""

# Build decision tree
depths = [5,10,15,20,25,30,35,40]
num_runs = 10
runs = np.zeros(shape=(len(depths),num_runs))

for i in range(len(depths)):
  for j in range(num_runs):
    depth = depths[i]
    tree = DecisionTreeRegressor(max_depth=depth)
    tree.fit(X_train,y_train)
    y_pred = tree.predict(X_test)

    # Computer the Mean square error of the results vs prediction
    mse = mean_squared_error(y_pred, y_test)
    runs[i][j] = mse

for i in range(len(depths)):
  avg_mse = sum(runs[i])/num_runs
  print('Depth: ' + str(depths[i]) + ' Average MSE: ' + str(avg_mse))

# Build decision tree
depths = [5,10,15,20,25,30,35,40]
num_runs = 10
runs = np.zeros(shape=(len(depths),num_runs))

for i in range(len(depths)):
  for j in range(num_runs):
    depth = depths[i]
    tree = DecisionTreeRegressor(max_depth=depth)
    tree.fit(X_train_1,y_train_1)
    y_pred = tree.predict(X_test_1)

    # Computer the Mean square error of the results vs prediction
    mse = mean_squared_error(y_pred, y_test_1)
    runs[i][j] = mse

for i in range(len(depths)):
  avg_mse = sum(runs[i])/num_runs
  print('Depth: ' + str(depths[i]) + ' Average MSE: ' + str(avg_mse))

"""Experimenting now on a Random Forest Regressor, we can notice that the MSE loss is better each time we increase the number of estimators and the max_depth of the trees. But this loss doesn't decrease at good rate even though the number of trees is doubled or tripled."""

# Build forest regressor
forest = RandomForestRegressor(n_estimators=100,
                             max_depth=30)

# train model
forest.fit(X_train,y_train)

y_pred = forest.predict(X_test)

# Computer the Mean square error of the results vs prediction
mse = mean_squared_error(y_pred, y_test)
print('mse: ', mse)

"""**XG boost**

RF is a bagging technique that trains multiple decision trees in parallel and determines the final output via a majority vote. XGBoost is a boosting technique that sequentially creates decision trees, each tree improving upon the mistakes of the previous one. The final result is a sum of outputs from all the trees.

Now let's try something similar to a Random Forest Regressor, which is XGBoost. XGBoost is a boosting technique which, similar to Random Forest, uses Decision Tree Regressors.

Random Forest trains multiple Decision Trees at the same time and the final vote is decided through a majority bote. But in XGBoost the trees


Let's install xgboost.
"""

!sudo pip install xgboost

import xgboost
print(xgboost.__version__)

# create an grading boosting regression model
gb_model = GradientBoostingRegressor()
# train model
gb_model.fit(X_train,y_train)

y_pred = gb_model.predict(X_test)

# Computer the Mean square error of the results vs prediction
mse = mean_squared_error(y_pred, y_test)
print('mse: ', mse)

# create an XG boost regression model
xgb_model = xgboost.XGBRegressor(max_depth=30)
# train model
xgb_model.fit(X_train,y_train)

y_pred = xgb_model.predict(X_test)

# Computer the Mean square error of the results vs prediction
mse = mean_squared_error(y_pred, y_test)
print('mse: ', mse)

"""## Neural Network architecture Experimentation

So far we have tried some
"""

def nn_exp_result(dataset_name, n_layers, n_units):
  print('Dataset: ', dataset_name)
  X_d, Y_d = get_data_dtc([dataset_name])
  X_train, X_test, y_train, y_test = train_test_split(X_d, Y_d, test_size=0.2,
                                                      random_state=2001)

  # Get loss for the baseline model
  baseline_preds, avg = baseline_model(y_train, y_test.shape)
  mse = mean_squared_error(baseline_preds, y_test)
  abs_error_b, rel_error_b = errors(mse,avg)

  model = create_NN_model_conf(n_layers=n_layers,n_units=n_units)

  #callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=10)
  history = model.fit(
    X_train,
    y_train,
    epochs=100,
    batch_size=32,
    validation_data=(X_test,y_test),
    #callbacks=[callback],
    verbose=1
    )

  history = pd.DataFrame(history.history)
  # Minimum validation loss reached through the epochs
  val_loss = history.loc[:,"val_loss"]
  min_val_loss = min(val_loss)
  abs_error, rel_error = errors(min_val_loss, avg)

  return [min_val_loss, abs_error, rel_error, rel_error_b]

"""Neural network experimentation. 8 hidden layers and 32 units."""

dataset_names = [dtc_bank_age, dtc_census_gender, dtc_census_race,
                 dtc_compas_gender, dtc_compas_race, dtc_credit_gender]

num_errors = 4
results = np.zeros((len(dataset_names),num_errors))

counter = 0
for dataset in dataset_names:
  result = nn_exp_result(dataset, n_layers=8, n_units=32)
  results[counter] = result
  counter += 1
  print('Val Loss: '+str(result[0])+', Abs. Error: '+str(result[1])+
        ', Rel error: '+str(result[2])+', Baseline Rel error: '+str(result[3]))
  print('**********************************************')

# Errors
for i in range(results.shape[0]):
  print('Dataset: ', dataset_names[i])
  print(results[i])

"""Neural Network experimentation. 16 hidden layers and 64 units."""

dataset_names = [dtc_bank_age, dtc_census_gender, dtc_census_race,
                 dtc_compas_gender, dtc_compas_race, dtc_credit_gender]

num_errors = 4
results_1 = np.zeros((len(dataset_names),num_errors))

counter = 0
for dataset in dataset_names:
  result = nn_exp_result(dataset, n_layers=16, n_units=64)
  results_1[counter] = result
  counter += 1
  print('Val Loss: '+str(result[0])+', Abs. Error: '+str(result[1])+
        ', Rel error: '+str(result[2])+', Baseline Rel error: '+str(result[3]))
  print('**********************************************')

# Errors
for i in range(results_1.shape[0]):
  print('Dataset: ', dataset_names[i])
  print(results_1[i])

"""## Random Forest Regressor Experimentation

One of the algorithms with the best performance in our experimentations so far was Random Forest Regressor. Let's try and experiment with different datasets resulting from different ML algorithms.

Let's see if the loss for Decision Tree Classifier - Census - Gender dataset maintains with different type of datasets like Logistic Regression, SVM, etc.
"""

"""
  Runs single experiment in only one dataset. The dataset is split into
  80-20 to training and testing sets. It builds a model with the specified
  ML model, then it predicts using this model on the testing set and outputs the
  relevant metrics such as MSE, R^2, etc.
"""
def ml_model_result(alg, dataset_name, ml_model):
  if alg == 'svm':
    get_data = get_data_svm
  elif alg == 'dtc':
    get_data = get_data_dtc
  elif alg == 'lr':
    get_data = get_data_lr
  elif alg == 'da':
    get_data = get_data_da
  elif alg == 'tr':
    get_data = get_data_tr

  X_d, Y_d = get_data([dataset_name])
  X_train, X_test, y_train, y_test = train_test_split(X_d, Y_d, test_size=0.2,
                                                      random_state=2001)

  # Get loss for the baseline model
  baseline_preds, avg = baseline_model(y_train, y_test.shape)
  mse = mean_squared_error(baseline_preds, y_test)
  abs_error_b, rel_error_b = errors(mse,avg)

  # Build ML model
  model = ml_model
  # Train model and predict
  model.fit(X_train,y_train)
  y_pred = model.predict(X_test)
  # Compute relevant errors and metrics
  r_2 = r2_score(y_true=y_test,y_pred=y_pred)
  mse = mean_squared_error(y_pred, y_test)
  abs_error, rel_error = errors(mse, avg)

  return [mse, abs_error, rel_error, r_2, rel_error_b]

"""
  Runs Experiment on multiple datasets with a specific ML model.
    Outputs the relevant metrics and errors e.g R^2 and loss error.
"""
def run_exp(alg, datasets, ml_model):
  num_errors = 5
  results = np.zeros((len(datasets),num_errors))
  counter = 0

  for dataset in datasets:
    print('Dataset: ', dataset)
    result = ml_model_result(alg, dataset, ml_model)
    results[counter] = result
    counter += 1
    print('Val Loss: '+str(result[0])+
          ', Abs. Error: '+str(result[1])+
          ', Rel error: '+str(result[2])+
          ', R^2: '+str(result[3])+
          ', Baseline Rel error: '+str(result[4]))
    print('**********************************************')
  return results

"""Random Forest. 100 trees and 35 as max depth."""

dtc_names = [dtc_bank_age, dtc_census_gender, dtc_census_race,
                 dtc_compas_gender, dtc_compas_race, dtc_credit_gender]

model = RandomForestRegressor(n_estimators=100, max_depth=35)
results = run_exp('dtc', dtc_names, model)

da_names = [da_bank_age, da_census_gender, da_census_race, da_compas_gender,
            da_compas_race, da_credit_gender]

model = RandomForestRegressor(n_estimators=100, max_depth=35)
results = run_exp('da', da_names, model)

lr_names = [lr_bank_age, lr_census_gender, lr_census_race,
                 lr_credit_gender]

model = RandomForestRegressor(n_estimators=100, max_depth=35)
results = run_exp('lr', lr_names, model)

svm_names = [svm_bank_age, svm_census_gender, svm_census_race,
              svm_compas_gender, svm_compas_race, svm_credit_gender]

model = RandomForestRegressor(n_estimators=100, max_depth=35)
results = run_exp('svm', svm_names, model)

tr_names = [tr_bank_age, tr_census_gender, tr_census_race,
            tr_compas_gender, tr_compas_race, tr_credit_gender]

model = RandomForestRegressor(n_estimators=100, max_depth=35)
results = run_exp('tr', tr_names, model)

"""Random Forest. 50 trees and 25 as max depth."""

tr_names = [tr_bank_age, tr_census_gender, tr_census_race,
            tr_compas_gender, tr_compas_race, tr_credit_gender]

model = RandomForestRegressor(n_estimators=50, max_depth=25)
results = run_exp('tr', tr_names, model)

"""XG Boost model with max depth of 30"""

def xg_boost_result(dataset_name, max_d):
  print('Dataset: ', dataset_name)
  X_d, Y_d = get_data_dtc([dataset_name])
  X_train, X_test, y_train, y_test = train_test_split(X_d, Y_d, test_size=0.2,
                                                      random_state=2001)

  # Get loss for the baseline model
  baseline_preds, avg = baseline_model(y_train, y_test.shape)
  mse = mean_squared_error(baseline_preds, y_test)
  abs_error_b, rel_error_b = errors(mse,avg)

  # create an XG boost regression model
  xgb_model = xgboost.XGBRegressor(max_depth=max_d)
  # train model
  xgb_model.fit(X_train,y_train)
  y_pred = xgb_model.predict(X_test)

  # Computer the Mean square error of the results vs prediction
  mse = mean_squared_error(y_pred, y_test)
  abs_error, rel_error = errors(mse, avg)

  return [mse, abs_error, rel_error, rel_error_b]

model = xgboost.XGBRegressor(max_depth=30)
results = run_exp('dtc', dtc_names, model)

"""## RQ1

Let's test our different ML algorithms on all the different datasets.
"""

dtc_names = [dtc_census_gender, dtc_census_race, dtc_compas_gender,
             dtc_compas_race, dtc_credit_gender, dtc_bank_age]

da_names = [da_census_gender, da_census_race, da_compas_gender,
            da_compas_race, da_credit_gender, da_bank_age]

lr_names = [lr_census_gender, lr_census_race, lr_compas_gender,
            lr_compas_race, lr_credit_gender, lr_bank_age]

svm_names = [svm_census_gender, svm_census_race, svm_compas_gender,
              svm_compas_race, svm_credit_gender, svm_bank_age]

tr_names = [tr_census_gender, tr_census_race, tr_compas_gender,
            tr_compas_race, tr_credit_gender, tr_bank_age]

all_dataset_names = dtc_names + lr_names +  tr_names + svm_names + da_names
strs = set()
for dataset in all_dataset_names:
  strs.add(dataset[0:3])

for strs_ in strs:
  print(strs_)

# Averages from matrix
def get_results(results_multiple_runs, length, num_store_values=6):
  num_store_values = num_store_values # 3 averages and 3 stdvs
  # num datasets x num models x num runs X num values to store
  results = np.zeros((results_multiple_runs.shape[0], num_store_values * length))
  avgs = np.average(results_multiple_runs, axis=2) # Get averages of result matrix
  stds = np.std(results_multiple_runs, axis=2) # Get standard deviations of result matrix
  print('avgs', avgs)
  print('stds', stds)
  print('avgs.shape', avgs.shape)
  print('stds.shape', stds.shape)
  # Traverse datasets
  for idx_d in range(results_multiple_runs.shape[0]):
    str_values = ''
    result_values = []
    # Traverse models
    for idx_m in range(results_multiple_runs.shape[1]):
      # Averages
      rel_rmse_avg = round(avgs[idx_d][idx_m][0], 3)
      rmse_avg = round(avgs[idx_d][idx_m][1], 3)
      r_2_avg = round(avgs[idx_d][idx_m][2], 3)
      # Standard Deviations
      rel_rmse_std = stds[idx_d][idx_m][0]
      rmse_std = stds[idx_d][idx_m][1]
      r_2_std = stds[idx_d][idx_m][2]

      # Print values
      str_values += '& %.3f (%.3f) & %.3f (%.3f) & %.3f (%.3f) ' % (rel_rmse_avg, rel_rmse_std, rmse_avg, rmse_std, r_2_avg, r_2_std)
      # Store values
      result_values.extend([rel_rmse_avg, rel_rmse_std, rmse_avg, rmse_std, r_2_avg, r_2_std])

    results[idx_d] = result_values
    print('Complete: ', str_values)
  return results

# Get model
def get_model(model_str, random_state):
  model = ''
  if model_str == 'svm':
    model = svm.NuSVR(kernel='rbf', gamma='auto', max_iter=10000)
  elif model_str == 'rf':
    model = RandomForestRegressor(n_estimators=100, max_depth=35)
  elif model_str == 'xgb':
    model = xgboost.XGBRegressor(max_depth=30)
  return model

"""### RQ1 ML algs"""

# RQ1 model experimenation runs
def rq1_model(models, random_states, all_dataset_names, y_col='AOD', num_runs=10):
  num_to_store = 3
  # num datasets x num models x num runs X num values to store
  results = np.zeros((len(all_dataset_names), len(models), num_runs, num_to_store))

  # Traverse through datasets
  for idx_d, dataset in enumerate(all_dataset_names):
    print('Dataset: ', dataset)
    alg = dataset[0:3]
    get_data = get_data_dtc
    if alg == 'SVM' or alg == 'SVM':
      print('SVM')
      get_data = get_data_svm
    elif alg == 'Dec' or alg == 'DTC':
      print('Decision Tree')
      get_data = get_data_dtc
    elif alg == 'Log' or alg == 'LRC':
      print('Logistic Regression')
      get_data = get_data_lr
    elif alg == 'Dis' or alg == 'DAC':
      get_data = get_data_da
      print('Discriminant Analysis')
    elif alg == 'Tre' or alg == 'TRC':
      print('Tree Regressor')
      get_data = get_data_tr
    # Traverse through models
    for idx_m, model_str in enumerate(models):
      # Traverse through number of runs
      for run in range(num_runs):
        # Get data with different splitting seed
        X_train, X_test, y_train, y_test = get_data([dataset], split=True, random_state=random_states[run], y_col=y_col)
        print('X_train.shape: ', X_train.shape)
        print('y_train.shape: ', y_train.shape)
        print('X_test.shape: ', X_test.shape)
        print('y_test.shape: ', y_test.shape)

        # Get loss for the baseline model
        baseline_preds_, avg_ = baseline_model(y_train, y_test.shape)
        mse_b_ = mean_squared_error(baseline_preds_, y_test)
        rmse_b, rel_rmse_b = errors(mse_b_,avg_)
        #r_2_b = r2_score(y_true=y_test,y_pred=baseline_preds_)

        # Fit model
        model = get_model(model_str, random_states[run])
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)

        # Compute relevant errors and metrics
        r_2 = r2_score(y_true=y_test, y_pred=y_pred)
        mse = mean_squared_error(y_pred, y_test)
        rmse, rel_rmse = errors(mse, avg_)

        result = [rel_rmse, rmse, r_2]
        # Store result. Idx of dataset and Num of run
        results[idx_d][idx_m][run] = result
        print(
              'Rel RMSE: '+str(result[0])+
              ', RMSE: '+str(result[1])+
              ', R^2: '+str(result[2])
              )
        print('**********************************************')
  return results

models = ['svm', 'rf', 'xgb']
random_states = [2001, 1500, 150, 768, 345, 876, 302, 450, 112, 2000]
results_rq1_model_1 = rq1_model(models, random_states, dtc_names, num_runs = 10)

# Print and store results!!
results = get_results(results_rq1_model_1, length=3)
print('Results: ', results)

models = ['svm', 'rf', 'xgb']
random_states = [2001, 1500, 150, 768, 345, 876, 302, 450, 112, 2000]
results_rq1_model_2 = rq1_model(models, random_states, lr_names, num_runs = 10)

# Print and store results!!
results_2 = get_results(results_rq1_model_2, length=3)
print('Results: ', results_2)

models = ['svm', 'rf', 'xgb']
random_states = [2001, 1500, 150, 768, 345, 876, 302, 450, 112, 2000]
results_rq1_model_3 = rq1_model(models, random_states, tr_names, num_runs = 10)
# Print and store results
results_3 = get_results(results_rq1_model_3, length=3)
print('Results: ', results_3)

models = ['svm', 'rf', 'xgb']
random_states = [2001, 1500, 150, 768, 345, 876, 302, 450, 112, 2000]
results_rq1_model_3 = rq1_model(models, random_states, svm_names, num_runs = 10)
# Print and store results
results_3 = get_results(results_rq1_model_3, length=3)
print('Results: ', results_3)

models = ['svm', 'rf', 'xgb']
random_states = [2001, 1500, 150, 768, 345, 876, 302, 450, 112, 2000]
results_rq1_model_5 = rq1_model(models, random_states, da_names, num_runs = 10)
# Print and store results
results_5 = get_results(results_rq1_model_5, length=3)
print('Results: ', results_5)

# Changing XGB random
models = ['xgb']
random_states = [2001, 1500, 150, 768, 345, 876, 302, 450, 112, 2000]
results_rq1_model_xgb = rq1_model(models, random_states, dtc_names + da_names, num_runs = 10)
# Print and store results
results_xgb = get_results(results_rq1_model_xgb, length=1)
print('Results: ', results_xgb)

# Changing XGB random
models = ['xgb']
random_states = [2001, 1500, 150, 768, 345, 876, 302, 450, 112, 2000]
results_rq1_model_xgb = rq1_model(models, random_states, lr_names, num_runs = 10)
# Print and store results
results_xgb = get_results(results_rq1_model_xgb, length=1)
print('Results: ', results_xgb)

"""### RQ1 NN"""

# Averages from matrix
def get_results_baseline(results_multiple_runs, num_store_values = 8):
  num_store_values = num_store_values # 4 averages and 4 stdvs
  # num datasets x num runs X num values to store
  results = np.zeros((results_multiple_runs.shape[0], num_store_values))
  avgs = np.average(results_multiple_runs, axis=1) # Get averages of result matrix
  stds = np.std(results_multiple_runs, axis=1) # Get standard deviations of result matrix
  print('avgs', avgs)
  print('stds', stds)
  print('avgs.shape', avgs.shape)
  print('stds.shape', stds.shape)
  # Traverse datasets
  for idx_d in range(results_multiple_runs.shape[0]):
    str_values = ''
    # Averages
    rel_error_b_avg = round(avgs[idx_d][0], 3)
    rel_error_avg = round(avgs[idx_d][1], 3)
    abs_error_avg = round(avgs[idx_d][2], 3)
    r_2_avg = round(avgs[idx_d][3], 3)
    # Standard Deviations
    rel_error_b_std = stds[idx_d][0]
    rel_error_std = stds[idx_d][1]
    abs_error_std = stds[idx_d][2]
    r_2_std = stds[idx_d][3]

    # Print values
    str_values += '& %.3f (%.3f) & %.3f (%.3f) & %.3f (%.3f) & %.3f (%.3f) ' % (rel_error_b_avg, rel_error_b_std, rel_error_avg, rel_error_std, abs_error_avg, abs_error_std, r_2_avg, r_2_std)
    # Store values
    result_values = [rel_error_b_avg, rel_error_b_std, rel_error_avg, rel_error_std, abs_error_avg, abs_error_std, r_2_avg, r_2_std]
    results[idx_d] = result_values
    print('Complete: ', str_values)

  return results

# RQ1 model experimenation runs
def rq1_nn(random_states, all_dataset_names, num_runs=10):
  num_to_store = 4
  # num datasets x num models x num runs X num values to store
  results = np.zeros((len(all_dataset_names), num_runs, num_to_store))

  # Traverse through datasets
  for idx_d, dataset in enumerate(all_dataset_names):
    print('Dataset: ', dataset)
    alg = dataset[0:3]
    get_data = get_data_dtc
    if alg == 'SVM':
      print('SVM')
      get_data = get_data_svm
    elif alg == 'Dec' or alg == 'DTC':
      print('Decision Tree')
      get_data = get_data_dtc
    elif alg == 'Log' or alg == 'LRC':
      print('Logistic Regression')
      get_data = get_data_lr
    elif alg == 'Dis' or alg == 'DAC':
      get_data = get_data_da
      print('Discriminant Analysis')
    elif alg == 'Tre' or alg == 'TRC':
      print('Tree Regressor')
      get_data = get_data_tr

    # Traverse through number of runs
    for run in range(num_runs):
      # Get data with different splitting seed
      X_train, X_test, y_train, y_test = get_data([dataset], split=True, random_state=random_states[run])
      print('X_train.shape: ', X_train.shape)
      print('y_train.shape: ', y_train.shape)
      print('X_test.shape: ', X_test.shape)
      print('y_test.shape: ', y_test.shape)

      # Get loss for the baseline model
      baseline_preds, avg = baseline_model(y_train, y_test.shape)
      mse_b = mean_squared_error(baseline_preds, y_test)
      abs_error_b, rel_error_b = errors(mse_b,avg)

      # Neural Network
      input_dim = X_train.shape[1] # Number of features
      model = create_NN_model_1(input_dim)
      print('input_dim: ', input_dim)

      # Store best model
      checkpoint_filepath = '/tmp/checkpoint'
      model_checkpoint = tf.keras.callbacks.ModelCheckpoint(
      filepath=checkpoint_filepath,
      save_weights_only=True,
      monitor='mean_squared_error',
      mode='min',
      save_best_only=True)

      history = model.fit(
        X_train,
        y_train,
        epochs=50,
        batch_size=64,
        callbacks = [model_checkpoint],
        verbose=1
      )
      model.load_weights(checkpoint_filepath) # Load weighst of best model

      y_pred = model.predict(X_test) # Predict on testing data

      # Compute relevant errors and metrics
      r_2 = r2_score(y_true=y_test, y_pred=y_pred)
      mse = mean_squared_error(y_pred, y_test)
      abs_error, rel_error = errors(mse, avg)

      result = [rel_error_b, rel_error, abs_error, r_2]
      # Store result. Idx of dataset and Num of run
      results[idx_d][run] = result
      print(
            'Rel error B.: '+str(result[0])+
            'Rel error: '+str(result[1])+
            ', Abs. Error: '+str(result[2])+
            ', R^2: '+str(result[3])
            )
      print('**********************************************')
  return results

random_states = [2001, 1500, 150, 768, 345, 876, 302, 450, 112, 2000]
results_rq1_nn_1 = rq1_nn(random_states, dtc_names, num_runs = 10)
# Print and store results
results_rq1_nn_1 = get_results_nn(results_rq1_nn_1, length=4)
print('Results: ', results_rq1_nn_1)

results_rq1_nn_1 = get_results_nn(results_rq1_nn_1)
print('Results: ', results_rq1_nn_1)

random_states = [2001, 1500, 150, 768, 345, 876, 302, 450, 112, 2000]
results_rq1_nn_2 = rq1_nn(random_states, lr_names, num_runs = 10)
# Print and store results
results_rq1_nn_2 = get_results_nn(results_rq1_nn_2)
print('Results: ', results_rq1_nn_2)

random_states = [2001, 1500, 150, 768, 345, 876, 302, 450, 112, 2000]
results_rq1_nn_3 = rq1_nn(random_states, tr_names, num_runs = 10)
# Print and store results
results_rq1_nn_3 = get_results_nn(results_rq1_nn_3)
print('Results: ', results_rq1_nn_3)

random_states = [2001, 1500, 150, 768, 345, 876, 302, 450, 112, 2000]
results_rq1_nn_4 = rq1_nn(random_states, svm_names, num_runs = 10)
# Print and store results
results_rq1_nn_4 = get_results_nn(results_rq1_nn_4)
print('Results: ', results_rq1_nn_4)

random_states = [2001, 1500, 150, 768, 345, 876, 302, 450, 112, 2000]
results_rq1_nn_5 = rq1_nn(random_states, da_names, num_runs = 10)
# Print and store results
results_rq1_nn_5 = get_results_nn(results_rq1_nn_5)
print('Results: ', results_rq1_nn_5)

"""## Mean Absolute Error

So far we have tried to run experiments with our main metric being MAE. Let's change this hyperparametr and compare metrics with MSE.

## Cross dataset experimentation

Until this point we have been working on predicting the AOD value within the same dataset. The dataset is split into a training and testing dataset (80-20 split) so we are predicting the values of the testing dataset which is only within one dataset.

A natural question occurs. What if we train our ML models with one dataset and then we predict the values of another dataset? Will the quality of the loss metric maintain or go down?

A similar experiment can be to use two datasets for training data instead of just one, and predict on another different dataset. In the first round of experiments we can observe that using just one dataset produces very bad results, with our baseline model performing better than the ML trained algorithm. Random Forest Regressor have produced great results on a single dataset, so let's find out if this is the best algorithm on cross-dataset experiment.

The following algorithms can be used to experiment cross-dataset experimentation:
* Random Forest Regressor
* XG Boost
* Neural Network
"""

def cross_ml_model_result(get_data, training_datasets, test_dataset, ml_model):
  # Merge training datasets into a single numpy array
  X_train, y_train = get_data([training_datasets])
  X_test, y_test = get_data([test_dataset])

  # Shuffle training data
  X_train, y_train = shuffle(X_train, y_train, random_state=2001)
  # Get loss for the baseline model
  baseline_preds, avg = baseline_model(y_test, y_test.shape)
  mse = mean_squared_error(baseline_preds, y_test)
  abs_error_b, rel_error_b = errors(mse,avg)

  # Build ML model
  model = ml_model
  # Train model and predict
  model.fit(X_train,y_train)
  y_pred = model.predict(X_test)
  # Compute relevant errors and metrics
  r_2 = r2_score(y_true=y_test,y_pred=y_pred)
  mse = mean_squared_error(y_pred, y_test)
  abs_error, rel_error = errors(mse, avg)

  return [mse, abs_error, rel_error, r_2, rel_error_b]

# Removed alg parameter
def cross_run_exp(list_training_datasets, list_testing_dataset, ml_model):
  num_errors = 5
  results = np.zeros((len(list_training_datasets),num_errors))
  counter = 0

  for i in range(len(list_training_datasets)):
    training_datasets = list_training_datasets[i]
    testing_dataset = list_testing_dataset[i]

    alg = testing_dataset[0:3]
    get_data = get_data_dtc
    if alg == 'SVM':
      print('SVM')
      get_data = get_data_svm
    elif alg == 'Dec':
      print('Decision Tree')
      get_data = get_data_dtc
    elif alg == 'Log':
      print('Logistic Regression')
      get_data = get_data_lr
    elif alg == 'Dis':
      get_data = get_data_da
      print('Discriminant Analysis')
    elif alg == 'Tre':
      print('Tree Regressor')
      get_data = get_data_tr

    print('Training datasets: ', training_datasets)
    print('Testing dataset: ', testing_dataset)
    result = cross_ml_model_result(get_data, training_datasets, testing_dataset, ml_model)
    results[counter] = result
    counter += 1
    print(
          'Baseline Rel error: '+str(result[4])+
          ', Rel error: '+str(result[2])+
          ', Abs. Error: '+str(result[1])+
          ', R^2: '+str(result[3])+
          ', Val Loss: '+str(result[0])
          )

    print('**********************************************')
  return results

dataset_names = [dtc_bank_age, dtc_census_gender, dtc_census_race,
                 dtc_compas_gender, dtc_compas_race, dtc_credit_gender]


training_datasets_1 = [dtc_census_gender]
testing_dataset_1 = dtc_compas_gender
result = cross_experimentation('dtc', training_datasets_1, testing_dataset_1)
print('Val Loss: '+str(result[0])+
      ', Abs. Error: '+str(result[1])+
      ', Rel error: '+str(result[2])+
      ', R^2: '+str(result[3])+
      ', Baseline Rel error: '+str(result[4]))
print('**********************************************')

training_datasets_2 = [dtc_compas_gender]
testing_dataset_2 = dtc_census_gender
result = cross_experimentation('dtc', training_datasets_2, testing_dataset_2)
print('Val Loss: '+str(result[0])+
      ', Abs. Error: '+str(result[1])+
      ', Rel error: '+str(result[2])+
      ', R^2: '+str(result[3])+
      ', Baseline Rel error: '+str(result[4]))
print('**********************************************')

training_datasets_3 = [dtc_compas_gender, dtc_census_gender]
testing_dataset_3 = dtc_census_race
result = cross_experimentation('dtc', training_datasets_3, testing_dataset_3)
print('Val Loss: '+str(result[0])+
      ', Abs. Error: '+str(result[1])+
      ', Rel error: '+str(result[2])+
      ', R^2: '+str(result[3])+
      ', Baseline Rel error: '+str(result[4]))
print('**********************************************')

training_datasets_4 = [dtc_compas_gender, dtc_census_gender]
testing_dataset_4 = dtc_credit_gender
result = cross_experimentation('dtc', training_datasets_4, testing_dataset_4)
print('Val Loss: '+str(result[0])+
      ', Abs. Error: '+str(result[1])+
      ', Rel error: '+str(result[2])+
      ', R^2: '+str(result[3])+
      ', Baseline Rel error: '+str(result[4]))
print('**********************************************')

training_datasets_5 = [dtc_compas_gender, dtc_census_gender, dtc_census_race]
testing_dataset_5 = dtc_credit_gender
result = cross_experimentation('dtc', training_datasets_5, testing_dataset_5)
print('Val Loss: '+str(result[0])+
      ', Abs. Error: '+str(result[1])+
      ', Rel error: '+str(result[2])+
      ', R^2: '+str(result[3])+
      ', Baseline Rel error: '+str(result[4]))
print('**********************************************')

training_datasets_5 = [dtc_compas_gender, dtc_credit_gender, dtc_compas_race]
testing_dataset_5 = dtc_census_gender
result = cross_experimentation('dtc', training_datasets_5, testing_dataset_5)
print('Val Loss: '+str(result[0])+
      ', Abs. Error: '+str(result[1])+
      ', Rel error: '+str(result[2])+
      ', R^2: '+str(result[3])+
      ', Baseline Rel error: '+str(result[4]))
print('**********************************************')

# Decision Tree Classifier lists for cross experimentation
dtc_list_training_datasets = [
    [dtc_bank_age, dtc_census_gender, dtc_census_race,
            dtc_compas_gender, dtc_compas_race],
    [dtc_bank_age, dtc_census_gender, dtc_census_race,
            dtc_compas_gender, dtc_credit_gender],
    [dtc_bank_age, dtc_census_gender, dtc_census_race,
            dtc_compas_race, dtc_credit_gender],
    [dtc_bank_age, dtc_census_gender, dtc_compas_gender,
            dtc_compas_race, dtc_credit_gender],
    [dtc_bank_age, dtc_census_race, dtc_compas_gender,
            dtc_compas_race, dtc_credit_gender],
    [dtc_census_gender, dtc_census_race, dtc_compas_gender,
            dtc_compas_race, dtc_credit_gender]
]

dtc_list_testing_datasets = [
    dtc_credit_gender,
    dtc_compas_race,
    dtc_compas_gender,
    dtc_census_race,
    dtc_census_gender,
    dtc_bank_age
]

# Discriminant Analysis lists for cross experimentation
da_list_training_datasets = [
    [da_bank_age, da_census_gender, da_census_race, da_compas_gender,
            da_compas_race],
    [da_bank_age, da_census_gender, da_census_race, da_compas_gender,
            da_credit_gender],
    [da_bank_age, da_census_gender, da_census_race, da_compas_race,
            da_credit_gender],
    [da_bank_age, da_census_gender, da_compas_gender, da_compas_race,
            da_credit_gender],
    [da_bank_age, da_census_race, da_compas_gender, da_compas_race,
            da_credit_gender],
    [da_census_gender, da_census_race, da_compas_gender,
            da_compas_race, da_credit_gender]
]

da_list_testing_datasets = [
    da_credit_gender,
    da_compas_race,
    da_compas_gender,
    da_census_race,
    da_census_gender,
    da_bank_age
]

# Logisitic Regression lists for cross experimentation
lr_list_training_datasets = [
    [lr_bank_age, lr_census_gender, lr_census_race],
    [lr_bank_age, lr_census_gender, lr_credit_gender],
    [lr_bank_age, lr_census_race, lr_credit_gender],
    [lr_census_gender, lr_census_race, lr_credit_gender]
]

lr_list_testing_datasets = [
    lr_credit_gender,
    lr_census_race,
    lr_census_gender,
    lr_bank_age
]

# Support Vector Machine lists for cross experimentation
svm_list_training_datasets = [
    [svm_bank_age, svm_census_gender, svm_census_race,
              svm_compas_gender, svm_compas_race],
    [svm_bank_age, svm_census_gender, svm_census_race,
              svm_compas_gender, svm_credit_gender],
    [svm_bank_age, svm_census_gender, svm_census_race,
              svm_compas_race, svm_credit_gender],
    [svm_bank_age, svm_census_gender, svm_compas_gender,
              svm_compas_race, svm_credit_gender],
    [svm_bank_age, svm_census_race, svm_compas_gender,
              svm_compas_race, svm_credit_gender],
    [svm_census_gender, svm_census_race, svm_compas_gender,
              svm_compas_race, svm_credit_gender]
]

svm_list_testing_datasets = [
    svm_credit_gender,
    svm_compas_race,
    svm_compas_gender,
    svm_census_race,
    svm_census_gender,
    svm_bank_age
]

# Tree Regressor lists for cross experimentation
tr_list_training_datasets = [
    [tr_bank_age, tr_census_gender, tr_census_race,
            tr_compas_gender, tr_compas_race],
    [tr_bank_age, tr_census_gender, tr_census_race,
            tr_compas_gender, tr_credit_gender],
    [tr_bank_age, tr_census_gender, tr_census_race,
            tr_compas_race, tr_credit_gender],
    [tr_bank_age, tr_census_gender, tr_compas_gender,
            tr_compas_race, tr_credit_gender],
    [tr_bank_age, tr_census_race, tr_compas_gender,
            tr_compas_race, tr_credit_gender],
    [tr_census_gender, tr_census_race, tr_compas_gender,
            tr_compas_race, tr_credit_gender]
]

tr_list_testing_datasets = [
    tr_credit_gender,
    tr_compas_race,
    tr_compas_gender,
    tr_census_race,
    tr_census_gender,
    tr_bank_age
]

# 1. DTC Random Forest cross-experimentation
model = RandomForestRegressor(n_estimators=100, max_depth=35)
results = cross_run_exp('dtc', dtc_list_training_datasets, dtc_list_testing_datasets, model)

# 2. DTC Random Forest cross-experimentation
xgb_model = xgboost.XGBRegressor(max_depth=30)
results = cross_run_exp('dtc', dtc_list_training_datasets, dtc_list_testing_datasets, xgb_model)

# 3. DTC Random Forest cross-experimentation
model =
results = cross_run_exp('dtc', dtc_list_training_datasets, dtc_list_testing_datasets, model)

# DA Random Forest cross-experimentation
model = RandomForestRegressor(n_estimators=100, max_depth=35)
results = cross_run_exp('da', da_list_training_datasets, da_list_testing_datasets, model)

# LR Random Forest cross-experimentation
model = RandomForestRegressor(n_estimators=100, max_depth=35)
results = cross_run_exp('lr', lr_list_training_datasets, lr_list_testing_datasets, model)

# SVM Random Forest cross-experimentation
model = RandomForestRegressor(n_estimators=100, max_depth=35)
results = cross_run_exp('svm', svm_list_training_datasets, svm_list_testing_datasets, model)

# SVM Random Forest cross-experimentation
model = RandomForestRegressor(n_estimators=50, max_depth=20)
results = cross_run_exp('svm', svm_list_training_datasets, svm_list_testing_datasets, model)

# TR Random Forest cross-experimentation
model = RandomForestRegressor(n_estimators=100, max_depth=35)
results = cross_run_exp('tr', tr_list_training_datasets, tr_list_testing_datasets, model)

"""# RQ2"""

"""
  Training datasets. Needs respective Testing dataset.
"""
dtc_rq2_training = [
    dtc_census_gender, dtc_census_race,
    dtc_compas_gender, dtc_compas_race
]
lr_rq2_training = [
    lr_census_gender, lr_census_race,
    lr_compas_gender, lr_compas_race
]
tr_rq2_training =[
    tr_census_gender, tr_census_race,
    tr_compas_gender, tr_compas_race
]
svm_rq2_training =[
    svm_census_gender, svm_census_race,
    svm_compas_gender, svm_compas_race
]
da_rq2_training =[
    da_census_gender, da_census_race,
    da_compas_gender, da_compas_race
]

"""
  Testing datasets. Needs respective Training dataset.
"""
dtc_rq2_testing = [
    dtc_census_race, dtc_census_gender,
    dtc_compas_race, dtc_compas_gender
]
lr_rq2_testing = [
    lr_census_race, lr_census_gender,
    lr_compas_race, lr_compas_gender
]
tr_rq2_testing = [
    tr_census_race, tr_census_gender,
    tr_compas_race, tr_compas_gender
]
svm_rq2_testing = [
    svm_census_race, svm_census_gender,
    svm_compas_race, svm_compas_gender,
    da_census_race, da_census_gender,
    da_compas_race, da_compas_gender
]
da_rq2_testing = [
    da_census_race, da_census_gender,
    da_compas_race, da_compas_gender
]

# Random Forest single-attribute Experimentation
model = RandomForestRegressor(n_estimators=100, max_depth=35)
results = cross_run_exp(list_rq2_training, list_rq2_testing, model)

# XG-Boost single-attribute Experimentation
model = svm.NuSVR(kernel='rbf', gamma='auto', max_iter=50000)
results = cross_run_exp(list_rq2_training, list_rq2_testing, model)

# Random Forest single-attribute Experimentation
model = svm.NuSVR(kernel='rbf', gamma='auto', max_iter=50000)
results = cross_run_exp(list_rq2_training, list_rq2_testing, model)

model = xgboost.XGBRegressor(max_depth=30)
results = cross_run_exp(list_rq2_training, list_rq2_testing, model)

"""#### RQ2 ML algs"""

"""
  Transforms downloaded data from a bytes format to Numpy arrays.
  Input: Name of files. Must be results from Decision Tree Classifier experiments.
  Output: X and Y numpy arrays
"""
def get_data_dtc_rq2(files, random_state=2001, enc=None, training=True):
  # One hot encoder that will represent categorical features
  ohe = OneHotEncoder()
  # Transforms data into a Pandas format, for easier manipulation
  training_data = pd.read_csv(io.BytesIO(uploaded[files[0]]))
  for i in range(1, len(files)-1):
    training_data = pd.concat([training_data, pd.read_csv(io.BytesIO(uploaded[files[i]]))])
  training_data = pd.concat([training_data, pd.read_csv(io.BytesIO(uploaded[files[len(files)-1]]))])

  # Columns we care about from the original dataset
  x_cols = ['max_depth', 'min_samples_split',
            'min_samples_leaf', 'min_weight_fraction_leaf']
  y_col = ['AOD']

  X_data = training_data[x_cols]
  X_data = X_data.replace({'max_depth': {np.nan:0}}) # Replaces nan values in max_depth column

  # Transforms data into X and Y numpys
  X_data = X_data.to_numpy()
  Y = training_data[y_col].to_numpy()

  # Will add columns that will be transformed into a One-Hot-Encoding
  X = training_data[['criterion', 'splitter', 'max_features']]

  ohe_enc = ohe.fit(X) if training else enc
  X_ohe = ohe_enc.transform(X).toarray()

  # Append these two datasets of the X data
  X = np.hstack((X_data, X_ohe))

  # Stack numpy arrays vertically
  XY = np.column_stack((X,Y))
  num_feas = XY.shape[1]-1

  XY = np.unique(XY, axis=0)
  X = XY[:,0:num_feas] # Features
  Y = XY[:,num_feas] # Output

  X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=random_state)
  if training:
    return X_train, X_test, y_train, y_test, ohe_enc
  return X_train, X_test, y_train, y_test

"""
  Transforms downloaded data from a bytes format to Numpy arrays.
  Input: Name of files. Must be results from Logistic Regression experiments.
  Output: X and Y numpy arrays
"""
def get_data_lr_rq2(files, random_state=2001, enc=None, training=True):
  # One hot encoder that will represent categorical features
  ohe = OneHotEncoder(handle_unknown='infrequent_if_exist')
  # Transforms data into a Pandas format, for easier manipulation
  # training_data = pd.concat(pd.read_csv(io.BytesIO(uploaded[file])) for file in files)
  training_data = pd.read_csv(io.BytesIO(uploaded[files[0]]))
  for i in range(1, len(files)-1):
    training_data = pd.concat([training_data, pd.read_csv(io.BytesIO(uploaded[files[i]]))])
  num_rows = training_data.shape[0]
  training_data = pd.concat([training_data, pd.read_csv(io.BytesIO(uploaded[files[len(files)-1]]))])

  # Columns we care about from the original dataset
  x_cols = ['tol', 'C', 'intercept_scaling', 'max_iteration', 'l1_ratio']
  y_col = ['AOD']
  X_data = training_data[x_cols]
  X_data = X_data.replace({'l1_ratio': {np.nan:0}}) # Replaces nan values in l1_ratio column

  # Transforms data into X and Y numpys
  X_data = X_data.to_numpy()
  Y = training_data[y_col].to_numpy()

  # Will add columns that will be transformed into a One-Hot-Encoding
  X = training_data[['solver', 'penalty', 'dual', 'fit_intercept', 'multi_class']]

  ohe_enc = ohe.fit(X) if training else enc
  X_ohe = ohe_enc.transform(X).toarray()

  # Append these two datasets of the X data
  X = np.hstack((X_data, X_ohe))

  # Stack numpy arrays vertically
  XY = np.column_stack((X,Y))
  num_feas = XY.shape[1]-1

  XY = np.unique(XY, axis=0)
  X = XY[:,0:num_feas] # Features
  Y = XY[:,num_feas] # Output

  X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=random_state)
  if training:
    return X_train, X_test, y_train, y_test, ohe_enc
  return X_train, X_test, y_train, y_test

"""
  Transforms downloaded data from a bytes format to Numpy arrays.
  Input: Name of files. Must be results from Tree Regressor experiments.
  Output: X and Y numpy arrays
"""
def get_data_tr_rq2(files, random_state=2001, enc=None, training=True):
  # One hot encoder that will represent categorical features
  ohe = OneHotEncoder(handle_unknown='infrequent_if_exist')
  # Transforms data into a Pandas format, for easier manipulation
  #training_data = pd.concat(pd.read_csv(io.BytesIO(uploaded[file])) for file in files)

  training_data = pd.read_csv(io.BytesIO(uploaded[files[0]]))
  for i in range(1, len(files)-1):
    training_data = pd.concat([training_data, pd.read_csv(io.BytesIO(uploaded[files[i]]))])
  num_rows = training_data.shape[0]
  training_data = pd.concat([training_data, pd.read_csv(io.BytesIO(uploaded[files[len(files)-1]]))])

  training_data = training_data[training_data['AOD'].notna()]
  # Columns we care about from the original dataset
  x_cols = ['max_depth', 'min_samples_split', 'min_samples_leaf',
            'min_weight_fraction_leaf', 'n_estimators', 'max_samples']
  y_col = ['AOD']
  X_data = training_data[x_cols]
  X_data = X_data.replace({'max_depth': {np.nan:0}}) # Replaces nan values in max_depth column
  #X_data = X_data.replace({'min_samples_split': {np.nan:0}})
  X_data = X_data.replace({'max_samples': {np.nan:0}})
  """
  X_data['min_samples_split'] = X_data['min_samples_split'].replace(np.nan, 0)
  X_data['max_samples'] = X_data['max_samples'].replace(np.nan, 0)"""
  # Transforms data into X and Y numpys
  X_data = X_data.to_numpy()

  Y = training_data[y_col].to_numpy()

  # Will add columns that will be transformed into a One-Hot-Encoding
  # Not using max_leaf_nodes, min_impurity_decrease, bootstrap, ccp_alpha
  X = training_data[['criterion', 'max_features', 'oob_score', 'warm_start']]

  ohe_enc = ohe.fit(X) if training else enc
  #if files[0] == 'TreeRegressor_compas_race_mutation_1628114319_res.csv' and not training:
  #  ohe_enc = ohe.fit(X)
  X_ohe = ohe_enc.transform(X).toarray()
  # Append these two datasets of the X data
  X = np.hstack((X_data, X_ohe))

  # Stack numpy arrays vertically
  XY = np.column_stack((X,Y))
  num_feas = XY.shape[1]-1

  XY = np.unique(XY, axis=0)
  X = XY[:,0:num_feas] # Features
  Y = XY[:,num_feas] # Output
  X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=random_state)
  if training:
    return X_train, X_test, y_train, y_test, ohe_enc
  return X_train, X_test, y_train, y_test

"""
  Transforms downloaded data from a bytes format to Numpy arrays.
  Input: Name of files. Must be results from Support Vector Machine experiments.
  Output: X and Y numpy arrays
"""
def get_data_svm_rq2(files, random_state=2001, enc=None, training=True):
  # One hot encoder that will represent categorical features
  ohe = OneHotEncoder()
  # Transforms data into a Pandas format, for easier manipulation
  #training_data = pd.concat(pd.read_csv(io.BytesIO(uploaded[file])) for file in files)
  training_data = pd.read_csv(io.BytesIO(uploaded[files[0]]))
  for i in range(1, len(files)-1):
    training_data = pd.concat([training_data, pd.read_csv(io.BytesIO(uploaded[files[i]]))])
  num_rows = training_data.shape[0]
  training_data = pd.concat([training_data, pd.read_csv(io.BytesIO(uploaded[files[len(files)-1]]))])

  training_data = training_data[training_data['AOD'].notna()]
  # Columns we care about from the original dataset
  x_cols = ['tol', 'C', 'intercept_scaling']
  y_col = ['AOD']
  X_data = training_data[x_cols]

  # Transforms data into X and Y numpys
  X_data = X_data.to_numpy()
  Y = training_data[y_col].to_numpy()

  # Will add columns that will be transformed into a One-Hot-Encoding
  # Not using multi_Class (all are ovr)
  X = training_data[['penalty', 'loss', 'degree', 'fit_intercept',
                     'class_weight']]

  ohe_enc = ohe.fit(X) if training else enc
  X_ohe = ohe_enc.transform(X).toarray()

  # Append these two datasets of the X data
  X = np.hstack((X_data, X_ohe))

  # Stack numpy arrays vertically
  XY = np.column_stack((X,Y))
  num_feas = XY.shape[1]-1

  XY = np.unique(XY, axis=0)
  X = XY[:,0:num_feas] # Features
  Y = XY[:,num_feas] # Output

  X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=random_state)
  if training:
    return X_train, X_test, y_train, y_test, ohe_enc
  return X_train, X_test, y_train, y_test

"""
  Transforms downloaded data from a bytes format to Numpy arrays.
  Input: Name of files. Must be results from Discriminant Analysis experiments.
  Output: X and Y numpy arrays
"""
def get_data_da_rq2(files, random_state=2001, enc=None, training=True):
  # One hot encoder that will represent categorical features
  ohe = OneHotEncoder()
  # Transforms data into a Pandas format, for easier manipulation
  #training_data = pd.concat(pd.read_csv(io.BytesIO(uploaded[file])) for file in files)
  training_data = pd.read_csv(io.BytesIO(uploaded[files[0]]))
  for i in range(1, len(files)-1):
    training_data = pd.concat([training_data, pd.read_csv(io.BytesIO(uploaded[files[i]]))])
  num_rows = training_data.shape[0]
  training_data = pd.concat([training_data, pd.read_csv(io.BytesIO(uploaded[files[len(files)-1]]))])

  # Columns we care about from the original dataset
  x_cols = ['tol', 'reg_param']
  y_col = ['AOD']
  X_data = training_data[x_cols]

  # Transforms data into X and Y numpys
  X_data = X_data.to_numpy()
  Y = training_data[y_col].to_numpy()

  # Will add columns that will be transformed into a One-Hot-Encoding
  X = training_data[['linear(0)_quadratic(1)', 'solver_Linear',
                     'Shrinkage_Linear', 'component', 'store_covariance',
                     'type_dataset']]

  ohe_enc = ohe.fit(X) if training else enc
  X_ohe = ohe_enc.transform(X).toarray()

  # Append these two datasets of the X data
  X = np.hstack((X_data, X_ohe))

  # Stack numpy arrays vertically
  XY = np.column_stack((X,Y))
  num_feas = XY.shape[1]-1

  XY = np.unique(XY, axis=0)
  X = XY[:,0:num_feas] # Features
  Y = XY[:,num_feas] # Output

  X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=random_state)
  if training:
    return X_train, X_test, y_train, y_test, ohe_enc
  return X_train, X_test, y_train, y_test

# Removed alg parameter
def rq2_model(models, random_states, list_training_datasets, list_testing_dataset):
  num_to_store = 3
  num_datasets = len(list_training_datasets)
  num_runs = len(random_states)
  # num datasets x num models x num runs X num values to store
  results = np.zeros((num_datasets, len(models), num_runs, num_to_store))

  for idx_d in range(num_datasets):
    training_datasets = list_training_datasets[idx_d]
    testing_dataset = list_testing_dataset[idx_d]

    alg = testing_dataset[0:3]
    get_data = get_data_dtc_rq2
    if alg == 'SVM':
      print('SVM')
      get_data = get_data_svm_rq2
    elif alg == 'Dec' or alg == 'DTC':
      print('Decision Tree')
      get_data = get_data_dtc_rq2
    elif alg == 'Log' or alg == 'LRC':
      print('Logistic Regression')
      get_data = get_data_lr_rq2
    elif alg == 'Dis' or alg == 'DAC':
      get_data = get_data_da_rq2
      print('Discriminant Analysis')
    elif alg == 'Tre' or alg == 'TRC':
      print('Tree Regressor')
      get_data = get_data_tr_rq2

    print('Training datasets: ', training_datasets)
    print('Testing dataset: ', testing_dataset)
    # Traverse through models
    for idx_m, model_str in enumerate(models):
      # Traverse through number of runs
      for run in range(num_runs):
        # Get data with different splitting seed
        if len(training_datasets) > 1:
          training = training_datasets
        else:
          training = [training_datasets]
        X_train, X_test_n, y_train, y_test_n, enc = get_data(training, random_state=random_states[run], enc=None, training=True)
        X_train_n, X_test, y_train_n, y_test = get_data([testing_dataset], random_state=random_states[run], enc=enc, training=False)

        # Get loss for the baseline model
        baseline_preds, avg = baseline_model(y_train, y_test.shape)
        mse_b = mean_squared_error(baseline_preds, y_test)
        abs_error_b, rel_error_b = errors(mse_b,avg)

        # Fit model
        model = get_model(model_str, random_states[run])
        model.fit(X_train, y_train)
        y_pred_original = model.predict(X_test)
        #y1_mean, y2_mean, y1_std, y2_std = get_means_stds(y_test_n, y_test)
        #y_pred = transformation_output(y_pred_original, y1_mean, y2_mean, y1_std, y2_std)
        y_pred= y_pred_original

        # Compute relevant errors and metrics
        r_2 = r2_score(y_true=y_test, y_pred=y_pred)
        mse = mean_squared_error(y_pred, y_test)
        abs_error, rel_error = errors(mse, avg)

        result = [rel_error, abs_error, r_2]
        # Store result. Idx of dataset and Num of run
        results[idx_d][idx_m][run] = result
        print(
              'Rel error: '+str(result[0])+
              ', Abs. Error: '+str(result[1])+
              ', R^2: '+str(result[2])
              )
        print('**********************************************')
  return results

models = ['svm', 'rf', 'xgb']
random_states = [2001, 1500, 150, 768, 345, 876, 302, 450, 112, 2000]
results_rq2_model_1 = rq2_model(models, random_states, dtc_rq2_training, dtc_rq2_testing)
# Print and store results!!
results = get_results(results_rq2_model_1, length=3)
print('Results: ', results)

models = ['rf', 'xgb']
random_states = [2001, 1500, 150, 768, 345, 876, 302, 450, 112, 2000]
results_rq2_model_1 = rq2_model(models, random_states, dtc_rq2_training, dtc_rq2_testing)
# Print and store results!!
results = get_results(results_rq2_model_1, length=2)
print('Results: ', results)

models = ['svm', 'rf', 'xgb']
random_states = [2001, 1500, 150, 768, 345, 876, 302, 450, 112, 2000]
results_rq2_model_2 = rq2_model(models, random_states, lr_rq2_training, lr_rq2_testing)
# Print and store results!!
results_2 = get_results(results_rq2_model_2, length=3)
print('Results: ', results_2)

models = ['svm', 'rf', 'xgb']
random_states = [2001, 1500, 150, 768, 345, 876, 302, 450, 112, 2000]
results_rq2_model_3 = rq2_model(models, random_states, tr_rq2_training, tr_rq2_testing)
#results_rq2_model_3 = rq2_model(models, random_states, [tr_compas_gender], [tr_compas_race])
# Print and store results!!
results_3 = get_results(results_rq2_model_3, length=3)
print('Results: ', results_3)

models = ['svm', 'rf', 'xgb']
random_states = [2001, 1500, 150, 768, 345, 876, 302, 450, 112, 2000]
results_rq2_model_4 = rq2_model(models, random_states, svm_rq2_training, svm_rq2_testing)
# Print and store results!!
results_4 = get_results(results_rq2_model_4, length=3)
print('Results: ', results_4)

models = ['svm', 'rf', 'xgb']
random_states = [2001, 1500, 150, 768, 345, 876, 302, 450, 112, 2000]
results_rq2_model_5 = rq2_model(models, random_states, da_rq2_training, da_rq2_testing)
# Print and store results!!
results_5 = get_results(results_rq2_model_5, length=3)
print('Results: ', results_5)

"""### RQ2 NN"""

# Removed alg parameter
def rq2_model(models, random_states, list_training_datasets, list_testing_dataset):
  num_to_store = 3
  num_datasets = len(list_training_datasets)
  num_runs = len(random_states)
  # num datasets x num models x num runs X num values to store
  results = np.zeros((num_datasets, len(models), num_runs, num_to_store))

  for idx_d in range(num_datasets):
    training_datasets = list_training_datasets[idx_d]
    testing_dataset = list_testing_dataset[idx_d]

    alg = testing_dataset[0:3]
    get_data = get_data_dtc_rq2
    if alg == 'SVM':
      print('SVM')
      get_data = get_data_svm_rq2
    elif alg == 'Dec':
      print('Decision Tree')
      get_data = get_data_dtc_rq2
    elif alg == 'Log':
      print('Logistic Regression')
      get_data = get_data_lr_rq2
    elif alg == 'Dis':
      get_data = get_data_da_rq2
      print('Discriminant Analysis')
    elif alg == 'Tre':
      print('Tree Regressor')
      get_data = get_data_tr_rq2

    print('Training datasets: ', training_datasets)
    print('Testing dataset: ', testing_dataset)
    # Traverse through models
    for idx_m, model_str in enumerate(models):
      # Traverse through number of runs
      for run in range(num_runs):
        # Get data with different splitting seed
        X_train, X_test_n, y_train, y_test_n, enc = get_data([training_datasets], random_state=random_states[run], enc=None, training=True)
        X_train_n, X_test, y_train_n, y_test = get_data([testing_dataset], random_state=random_states[run], enc=enc, training=False)

        # Get loss for the baseline model
        baseline_preds, avg = baseline_model(y_train, y_test.shape)
        mse_b = mean_squared_error(baseline_preds, y_test)
        abs_error_b, rel_error_b = errors(mse_b,avg)

        # Fit model
        model = get_model(model_str, random_states[run])
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)

        # Compute relevant errors and metrics
        r_2 = r2_score(y_true=y_test, y_pred=y_pred)
        mse = mean_squared_error(y_pred, y_test)
        abs_error, rel_error = errors(mse, avg)

        result = [rel_error, abs_error, r_2]
        # Store result. Idx of dataset and Num of run
        results[idx_d][idx_m][run] = result
        print(
              'Rel error: '+str(result[0])+
              ', Abs. Error: '+str(result[1])+
              ', R^2: '+str(result[2])
              )
        print('**********************************************')
  return results

# RQ1 model experimenation runs
def rq2_nn(random_states, list_training_datasets, list_testing_dataset):
  num_to_store = 4
  num_datasets = len(list_training_datasets)
  num_runs = len(random_states)
  # num datasets x num runs X num values to store
  results = np.zeros((num_datasets, num_runs, num_to_store))

  # Traverse through datasets
  for idx_d in range(num_datasets):
    training_datasets = list_training_datasets[idx_d]
    testing_dataset = list_testing_dataset[idx_d]
    alg = testing_dataset[0:3]
    get_data = get_data_dtc_rq2
    if alg == 'SVM':
      print('SVM')
      get_data = get_data_svm_rq2
    elif alg == 'Dec' or alg == 'DTC':
      print('Decision Tree')
      get_data = get_data_dtc_rq2
    elif alg == 'Log' or alg == 'LRC':
      print('Logistic Regression')
      get_data = get_data_lr_rq2
    elif alg == 'Dis' or alg == 'DAC':
      get_data = get_data_da_rq2
      print('Discriminant Analysis')
    elif alg == 'Tre' or alg == 'TRC':
      print('Tree Regressor')
      get_data = get_data_tr_rq2


    print('Training datasets: ', training_datasets)
    print('Testing dataset: ', testing_dataset)
    # Traverse through number of runs
    for run in range(num_runs):
      # Get data with different splitting seed
      X_train, X_test_n, y_train, y_test_n, enc = get_data([training_datasets], random_state=random_states[run], enc=None, training=True)
      X_train_n, X_test, y_train_n, y_test = get_data([testing_dataset], random_state=random_states[run], enc=enc, training=False)
      print('X_train.shape: ', X_train.shape)
      print('y_train.shape: ', y_train.shape)
      print('X_test.shape: ', X_test.shape)
      print('y_test.shape: ', y_test.shape)

      # Get loss for the baseline model
      baseline_preds, avg = baseline_model(y_train, y_test.shape)
      mse_b = mean_squared_error(baseline_preds, y_test)
      abs_error_b, rel_error_b = errors(mse_b,avg)

      # Neural Network
      input_dim = X_train.shape[1] # Number of features
      model = create_NN_model_1(input_dim)

      # Store best model
      checkpoint_filepath = '/tmp/checkpoint'
      model_checkpoint = tf.keras.callbacks.ModelCheckpoint(
      filepath=checkpoint_filepath,
      save_weights_only=True,
      monitor='mean_squared_error',
      mode='min',
      save_best_only=True)

      history = model.fit(
        X_train,
        y_train,
        epochs=50,
        batch_size=64,
        callbacks = [model_checkpoint],
        verbose=1
      )
      model.load_weights(checkpoint_filepath) # Load weighst of best model

      y_pred = model.predict(X_test) # Predict on testing data

      # Compute relevant errors and metrics
      r_2 = r2_score(y_true=y_test, y_pred=y_pred)
      mse = mean_squared_error(y_pred, y_test)
      abs_error, rel_error = errors(mse, avg)

      result = [rel_error_b, rel_error, abs_error, r_2]
      # Store result. Idx of dataset and Num of run
      results[idx_d][run] = result
      print(
            'Rel error B.: '+str(result[0])+
            ', Rel error: '+str(result[1])+
            ', Abs. Error: '+str(result[2])+
            ', R^2: '+str(result[3])
            )
      print('**********************************************')
  return results

random_states = [2001, 1500, 150, 768, 345, 876, 302, 450, 112, 2000]
results_rq2_nn_1 = rq2_nn(random_states, dtc_rq2_training, dtc_rq2_testing)
# Print and store results
results_rq2_nn_1 = get_results_nn(results_rq2_nn_1, length=4)
print('Results: ', results_rq2_nn_1)

results_rq2_nn_1 = get_results_nn(results_rq2_nn_1, num_store_values = 8)
print('Results: ', results_rq2_nn_1)

datasets_training = lr_rq2_training + tr_rq2_training + svm_rq2_training + da_rq2_training
datasets_testing = lr_rq2_testing + tr_rq2_testing + svm_rq2_testing + da_rq2_testing
random_states = [2001, 1500, 150, 768, 345, 876, 302, 450, 112, 2000]
results_rq2_nn_2 = rq2_nn(random_states, datasets_training, datasets_testing)
# Print and store results
results_rq2_nn_2 = get_results_nn(results_rq2_nn_2, num_store_values = 8)
print('Results: ', results_rq2_nn_2)

"""# RQ3

Options for RQ3
"""

models = ['rf']
random_states = [2001, 1500, 150, 768, 345, 876, 302, 450, 112, 2000]
results_rq3_model_1 = rq2_model(models, random_states, [dtc_compas_gender], [dtc_census_gender])
# Print and store results!!
results = get_results(results_rq3_model_1, length=1)
print('Results: ', results)

models = ['rf']
random_states = [2001, 1500, 150, 768, 345, 876, 302, 450, 112, 2000]
results_rq3_model_1 = rq2_model(models, random_states, [dtc_census_gender], [dtc_compas_gender])
# Print and store results!!
results = get_results(results_rq3_model_1, length=1)
print('Results: ', results)

model = RandomForestRegressor(n_estimators=100, max_depth=35)
X_train, X_test, y_train, y_test, ohe_enc = get_data_dtc_rq2([dtc_census_gender,dtc_compas_gender], training=True)

# Get loss for the baseline model
baseline_preds, avg = baseline_model(y_train, y_test.shape)
mse_b = mean_squared_error(baseline_preds, y_test)
abs_error_b, rel_error_b = errors(mse_b,avg)

# Fit model
model.fit(X_train, y_train)
y_pred = model.predict(X_test)

# Compute relevant errors and metrics
r_2 = r2_score(y_true=y_test, y_pred=y_pred)
mse = mean_squared_error(y_pred, y_test)
abs_error, rel_error = errors(mse, avg)

result = [rel_error, abs_error, r_2]
# Store result. Idx of dataset and Num of run
print(
      'Rel error: '+str(result[0])+
      ', Abs. Error: '+str(result[1])+
      ', R^2: '+str(result[2])
      )
print('**********************************************')

"""
  RQ3 dataset experiments. With same protected attribute.
"""
dtc_rq3 = [
    [dtc_census_gender, dtc_compas_gender],
    [dtc_census_race, dtc_compas_race],
    [dtc_census_gender, dtc_compas_gender, dtc_credit_gender]
]

lr_rq3 = [
    [lr_census_gender, lr_compas_gender],
    [lr_census_race, lr_compas_race],
    [lr_census_gender, lr_compas_gender, lr_credit_gender]
]

tr_rq3 = [
    [tr_census_gender, tr_compas_gender],
    [tr_census_race, tr_compas_race],
    [tr_census_gender, tr_compas_gender, tr_credit_gender]
]

svm_rq3 = [
    [svm_census_gender, svm_compas_gender],
    [svm_census_race, svm_compas_race],
    [svm_census_gender, svm_compas_gender, svm_credit_gender]
]

da_rq3 = [
    [da_census_gender, da_compas_gender],
    [da_census_race, da_compas_race],
    [da_census_gender, da_compas_gender, da_credit_gender]
]

all_datasets_rq3 = dtc_rq3 + lr_rq3 + tr_rq3 + svm_rq3 + da_rq3

"""### RQ3 ML algs"""

# RQ3 model experimenation runs
def rq3_model(models, random_states, all_dataset_names, num_runs=10):
  num_to_store = 3
  # num exps x num models x num runs X num values to store
  results = np.zeros((len(all_dataset_names), len(models), num_runs, num_to_store))

  # Traverse through datasets
  for idx_d, datasets in enumerate(all_dataset_names):
    print('Dataset: ', datasets)
    alg = datasets[0][0:3] # Select just one dataset
    if alg == 'SVM':
      print('SVM')
      get_data = get_data_svm
    elif alg == 'Dec':
      print('Decision Tree')
      get_data = get_data_dtc
    elif alg == 'Log':
      print('Logistic Regression')
      get_data = get_data_lr
    elif alg == 'Dis':
      get_data = get_data_da
      print('Discriminant Analysis')
    elif alg == 'Tre':
      print('Tree Regressor')
      get_data = get_data_tr
    # Traverse through models
    for idx_m, model_str in enumerate(models):
      # Traverse through number of runs
      for run in range(num_runs):
        # Get data with different splitting seed
        X_train, X_test, y_train, y_test = get_data(datasets, split=True, random_state=random_states[run])
        print('X_train.shape: ', X_train.shape)
        print('y_train.shape: ', y_train.shape)
        print('X_test.shape: ', X_test.shape)
        print('y_test.shape: ', y_test.shape)

        # Get loss for the baseline model
        baseline_preds, avg = baseline_model(y_train, y_test.shape)
        mse_b = mean_squared_error(baseline_preds, y_test)
        abs_error_b, rel_error_b = errors(mse_b,avg)

        # Fit model
        model = get_model(model_str, random_states[run])
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)

        # Compute relevant errors and metrics
        r_2 = r2_score(y_true=y_test, y_pred=y_pred)
        mse = mean_squared_error(y_pred, y_test)
        abs_error, rel_error = errors(mse, avg)

        result = [rel_error, abs_error, r_2]
        # Store result. Idx of dataset and Num of run
        results[idx_d][idx_m][run] = result
        print(
              'Rel error: '+str(result[0])+
              ', Abs. Error: '+str(result[1])+
              ', R^2: '+str(result[2])
              )
        print('**********************************************')
  return results

models = ['rf', 'xgb']
random_states = [2001, 1500, 150, 768, 345, 876, 302, 450, 112, 2000]
results_rq3 = rq3_model(models, random_states, all_datasets_rq3, num_runs = 10)
# Print and store results
print('Results: ', results_rq3)
results_rq3_ = get_results(results_rq3, length=3)
print('Results: ', results_rq3_)

results_rq3_ = get_results(results_rq3, length=2)
print('Results: ', results_rq3_)

models = ['svm']
random_states = [2001, 1500, 150, 768, 345, 876, 302, 450, 112, 2000]
results_rq3_svm = rq3_model(models, random_states, dtc_rq3+lr_rq3, num_runs = 10)
# Print and store results
print('Results: ', results_rq3_svm)
results_rq3_wvm_ = get_results(results_rq3_svm, length=1)
print('Results: ', results_rq3_)

models = ['svm']
random_states = [2001, 1500, 150, 768, 345, 876, 302, 450, 112, 2000]
results_rq3_svm = rq3_model(models, random_states, svm_rq3 + tr_rq3, num_runs = 10)
# Print and store results
print('Results: ', results_rq3_svm)
results_rq3_wvm_ = get_results(results_rq3_svm, length=1)
print('Results: ', results_rq3_svm)

models = ['svm']
random_states = [2001, 1500, 150, 768, 345, 876, 302, 450, 112, 2000]
results_rq3_svm = rq3_model(models, random_states, da_rq3, num_runs = 10)
# Print and store results
print('Results: ', results_rq3_svm)
results_rq3_svm = get_results(results_rq3_svm, length=1)
print('Results: ', results_rq3_svm)

"""### RQ3 NN"""

# RQ1 model experimenation runs
def rq3_nn(random_states, all_dataset_names, num_runs=10):
  num_to_store = 4
  # num datasets x num models x num runs X num values to store
  results = np.zeros((len(all_dataset_names), num_runs, num_to_store))

  # Traverse through datasets
  for idx_d, datasets in enumerate(all_dataset_names):
    print('Dataset: ', datasets)
    alg = datasets[0][0:3]
    if alg == 'SVM':
      print('SVM')
      get_data = get_data_svm
    elif alg == 'Dec':
      print('Decision Tree')
      get_data = get_data_dtc
    elif alg == 'Log':
      print('Logistic Regression')
      get_data = get_data_lr
    elif alg == 'Dis':
      get_data = get_data_da
      print('Discriminant Analysis')
    elif alg == 'Tre':
      print('Tree Regressor')
      get_data = get_data_tr

    # Traverse through number of runs
    for run in range(num_runs):
      # Get data with different splitting seed
      X_train, X_test, y_train, y_test = get_data(datasets, split=True, random_state=random_states[run])
      print('X_train.shape: ', X_train.shape)
      print('y_train.shape: ', y_train.shape)
      print('X_test.shape: ', X_test.shape)
      print('y_test.shape: ', y_test.shape)

      # Get loss for the baseline model
      baseline_preds, avg = baseline_model(y_train, y_test.shape)
      mse_b = mean_squared_error(baseline_preds, y_test)
      abs_error_b, rel_error_b = errors(mse_b,avg)

      # Neural Network
      input_dim = X_train.shape[1] # Number of features
      model = create_NN_model_1(input_dim)
      print('input_dim: ', input_dim)

      # Store best model
      checkpoint_filepath = '/tmp/checkpoint'
      model_checkpoint = tf.keras.callbacks.ModelCheckpoint(
      filepath=checkpoint_filepath,
      save_weights_only=True,
      monitor='mean_squared_error',
      mode='min',
      save_best_only=True)

      history = model.fit(
        X_train,
        y_train,
        epochs=50,
        batch_size=64,
        callbacks = [model_checkpoint],
        verbose=1
      )
      model.load_weights(checkpoint_filepath) # Load weighst of best model

      y_pred = model.predict(X_test) # Predict on testing data

      # Compute relevant errors and metrics
      r_2 = r2_score(y_true=y_test, y_pred=y_pred)
      mse = mean_squared_error(y_pred, y_test)
      abs_error, rel_error = errors(mse, avg)

      result = [rel_error_b, rel_error, abs_error, r_2]
      # Store result. Idx of dataset and Num of run
      results[idx_d][run] = result
      print(
            'Rel error B.: '+str(result[0])+
            'Rel error: '+str(result[1])+
            ', Abs. Error: '+str(result[2])+
            ', R^2: '+str(result[3])
            )
      print('**********************************************')
  return results

random_states = [2001, 1500, 150, 768, 345, 876, 302, 450, 112, 2000]
results_rq3_nn = rq3_nn(random_states, dtc_rq3 + lr_rq3, num_runs = 10)
# Print and store results
results_rq3_nn = get_results_nn(results_rq3_nn)
print('Results: ', results_rq3_nn)

random_states = [2001, 1500, 150, 768, 345, 876, 302, 450, 112, 2000]
results_rq3_nn = rq3_nn(random_states, tr_rq3 + svm_rq3 + da_rq3, num_runs = 10)
# Print and store results
results_rq3_nn = get_results_nn(results_rq3_nn)
print('Results: ', results_rq3_nn)

"""# RQ4"""

"""
  Training datasets. Needs respective Testing dataset.
"""
"""
    [dtc_census_gender, dtc_credit_gender],
    [dtc_compas_gender, dtc_credit_gender],
    [dtc_census_gender, dtc_compas_gender]
    , dtc_compas_gender,
    dtc_credit_gender, dtc_credit_gender,
    dtc_census_gender, dtc_compas_gender,
    dtc_census_race, dtc_census_gender
"""

dtc_rq4_training = [
    dtc_credit_gender
]

"""dtc_rq4_testing = [
    dtc_compas_gender, dtc_census_gender, dtc_credit_gender
]"""

da_rq4_training = [
    da_census_gender, da_compas_gender,
    da_credit_gender, da_credit_gender,
    da_census_race, da_census_gender,
    da_census_gender, da_compas_gender
]

lr_rq4_training = [
    lr_census_gender, lr_compas_gender,
    lr_credit_gender, lr_credit_gender,
    lr_census_race, lr_census_gender,
    lr_census_gender, lr_compas_gender
]

svm_rq4_training = [
    svm_census_gender, svm_compas_gender,
    svm_credit_gender, svm_credit_gender,
    svm_census_race, svm_census_gender,
    svm_census_gender, svm_compas_gender
]

tr_rq4_training = [
    tr_census_gender, tr_compas_gender,
    tr_credit_gender, tr_credit_gender,
    tr_census_race, tr_census_gender,
    tr_census_gender, tr_compas_gender
]


"""
  Testing datasets. Needs respective Training dataset.
"""
"""dtc_compas_gender, dtc_census_gender,
    dtc_census_gender, dtc_compas_gender,
    dtc_credit_gender, dtc_credit_gender,
    dtc_compas_race, dtc_census_race
    , dtc_census_gender,
    dtc_census_gender, dtc_compas_gender,
    dtc_credit_gender, dtc_credit_gender,
    dtc_compas_race, dtc_census_race"""
dtc_rq4_testing = [
    dtc_compas_gender
]

da_rq4_testing = [
    da_compas_gender, da_census_gender,
    da_census_gender, da_compas_gender,
    da_compas_race, da_census_race,
    da_credit_gender, da_credit_gender
]

lr_rq4_testing = [
    lr_compas_gender, lr_census_gender,
    lr_census_gender, lr_compas_gender,
    lr_compas_race, lr_census_race,
    lr_credit_gender, lr_credit_gender
]

svm_rq4_testing = [
    svm_compas_gender, svm_census_gender,
    svm_census_gender, svm_compas_gender,
    svm_compas_race, svm_census_race,
    svm_credit_gender, svm_credit_gender
]

tr_rq4_testing = [
    tr_compas_gender, tr_census_gender,
    tr_census_gender, tr_compas_gender,
    tr_compas_race, tr_census_race,
    tr_credit_gender, tr_credit_gender
]

"""## RQ4 ML algs"""

# Transformation of prediction outputs
def transformation_output(original_preds, y1_mean, y2_mean, y1_std, y2_std):
  scaled_preds = (original_preds - y1_mean) * (y2_std/y1_std) + y2_mean
  return scaled_preds

# Get means and stds of prediction outputs
def get_means_stds(y1, y2):
  y1_mean = np.mean(y1)
  y2_mean = np.mean(y2)
  y1_std = np.std(y1)
  y2_std = np.std(y2)
  return y1_mean, y2_mean, y1_std, y2_std

def graph_preds_comp(y_preds, y_expected):
  # Plotting the data
  plt.scatter(y_preds, y_expected, marker='o', linestyle='-')

  # Adding labels and title
  plt.xlabel('X-axis Label')
  plt.ylabel('Y-axis Label')
  plt.title('Plot of Y against X')
  plt.show()
  return


# RQ4 model experimenation runs
def rq4_model(models, random_states, training_datasets, testing_datasets, num_runs=10):
  num_to_store = 3
  # num exps x num models x num runs X num values to store
  results = np.zeros((len(training_datasets), len(models), num_runs, num_to_store))

  # Traverse through datasets
  for idx_d in range(len(training_datasets)):
    training_dataset = training_datasets[idx_d]
    testing_dataset = testing_datasets[idx_d]
    print('Training Dataset: ', training_dataset)
    print('Testing dataset: ', testing_dataset)
    alg = training_dataset[0][0:3] # Select just one dataset
    get_data = get_data_dtc_rq2
    if alg == 'SVM':
      print('SVM')
      get_data = get_data_svm_rq2
    elif alg == 'Dec':
      print('Decision Tree')
      get_data = get_data_dtc_rq2
    elif alg == 'Log':
      print('Logistic Regression')
      get_data = get_data_lr_rq2
    elif alg == 'Dis':
      get_data_testing = get_data_da_rq2
      print('Discriminant Analysis')
    elif alg == 'Tre':
      print('Tree Regressor')
      get_data = get_data_tr_rq2
    # Traverse through models
    for idx_m, model_str in enumerate(models):
      # Traverse through number of runs
      for run in range(num_runs):
        # Get data with different splitting seed
        X_train, X_test_n, y_train, y_test_n, enc = get_data([training_dataset], random_state=random_states[run], enc=None, training=True)
        X_train_n, X_test, y_train_n, y_test = get_data([testing_dataset], random_state=random_states[run], enc=enc, training=False)

        print('X_train.shape: ', X_train.shape)
        print('y_train.shape: ', y_train.shape)
        print('X_test.shape: ', X_test.shape)
        print('y_test.shape: ', y_test.shape)

        # Get loss for the baseline model
        baseline_preds, avg = baseline_model(y_train, y_test.shape)
        mse_b = mean_squared_error(baseline_preds, y_test)
        abs_error_b, rel_error_b = errors(mse_b,avg)

        # Fit model
        model = get_model(model_str, random_states[run])
        model.fit(X_train, y_train)
        y_pred_original = model.predict(X_test)
        #y1_mean, y2_mean, y1_std, y2_std = get_means_stds(y_test_n, y_test)
        #y_pred = transformation_output(y_pred_original, y1_mean, y2_mean, y1_std, y2_std)
        y_pred = y_pred_original

        # Compute relevant errors and metrics
        r_2 = r2_score(y_true=y_test, y_pred=y_pred)
        mse = mean_squared_error(y_pred, y_test)
        abs_error, rel_error = errors(mse, avg)

        result = [rel_error, abs_error, r_2]
        # Store result. Idx of dataset and Num of run
        results[idx_d][idx_m][run] = result
        print(
              'Rel error: '+str(result[0])+
              ', Abs. Error: '+str(result[1])+
              ', R^2: '+str(result[2])
              )
        print('**********************************************')
        graph_preds_comp(y_pred, y_test)

  return results

"""
  Decision Tree Classifier
"""
models = ['rf', 'xgb']
random_states = [2001, 1500, 150, 768, 345, 876, 302, 450, 112, 2000]
results_rq4_1= rq4_model(models, random_states, dtc_rq4_training, dtc_rq4_testing)
# Print and store results!!
results = get_results(results_rq4_1, length=2)
print('Results: ', results)

"""
  Decision Tree Classifier
"""
models = ['rf', 'xgb']
random_states = [2001, 1500, 150, 768, 345, 876, 302, 450, 112, 2000]
results_rq4_1= rq4_model(models, random_states, dtc_rq4_training, dtc_rq4_testing)
# Print and store results!!
results = get_results(results_rq4_1, length=2)
print('Results: ', results)

"""
  Decision Tree Classifier
"""
models = ['rf', 'xgb']
random_states = [2001, 1500, 150, 768, 345, 876, 302, 450, 112, 2000]
results_rq4_1= rq2_model(models, random_states, dtc_rq4_training, dtc_rq4_testing)
# Print and store results!!
results = get_results(results_rq4_1, length=2)
print('Results: ', results)

"""
  Decision Tree Classifier
"""

models = ['rf', 'xgb']
random_states = [2001, 1500, 150, 768, 345, 876, 302, 450, 112, 2000]
results_rq4_1= rq2_model(models, random_states, dtc_rq4_training, dtc_rq4_testing)
# Print and store results!!
results = get_results(results_rq4_1, length=2)
print('Results: ', results)

"""
  Discriminant Analysis
"""
models = ['rf', 'xgb']
random_states = [2001, 1500, 150, 768, 345, 876, 302, 450, 112, 2000]
results_rq4_2 = rq2_model(models, random_states, da_rq4_training, da_rq4_testing)
# Print and store results!!
results = get_results(results_rq4_2, length=2)
print('Results: ', results)

models = ['rf', 'xgb']
random_states = [2001, 1500, 150, 768, 345, 876, 302, 450, 112, 2000]
results_rq4_svm= rq2_model(models, random_states, svm_rq4_training, svm_rq4_testing)
# Print and store results!!
results = get_results(results_rq4_svm, length=2)
print('Results: ', results)

models = ['rf', 'xgb']
random_states = [2001, 1500, 150, 768, 345, 876, 302, 450, 112, 2000]
results_rq4_tr = rq2_model(models, random_states, tr_rq4_training, tr_rq4_testing)
# Print and store results!!
results = get_results(results_rq4_tr, length=2)
print('Results: ', results)

"""# Running times"""

# Averages from matrix
def get_times(results_multiple_runs, length, num_store_values = 3):
  num_store_values = num_store_values # Len of data, duration avg, duration std
  # num datasets x num models x num runs X num values to store
  results = np.zeros((results_multiple_runs.shape[0], 3 * length))
  avgs = np.average(results_multiple_runs, axis=2) # Get averages of result matrix
  stds = np.std(results_multiple_runs, axis=2) # Get standard deviations of result matrix
  print('avgs', avgs)
  print('stds', stds)
  print('avgs.shape', avgs.shape)
  print('stds.shape', stds.shape)
  # Traverse datasets
  for idx_d in range(results_multiple_runs.shape[0]):
    result_values = []
    # Traverse models (RF and XGBoost)
    for idx_m in range(results_multiple_runs.shape[1]):
      # Averages
      len_avg = int(avgs[idx_d][idx_m][0])
      durations_avg = round(avgs[idx_d][idx_m][1], 3)
      # Standard Deviations
      durations_std = stds[idx_d][idx_m][1]
      # Store values
      result_values.extend([len_avg, durations_avg, durations_std])

    results[idx_d] = result_values # For each dataset
  return results

# RQ1 model experimenation runs
def rq1_model_time(models, random_states, all_dataset_names, num_runs=10):
  nums_to_store = 2 # len(data) and duration
  # num datasets x num models x num runs x nums_to_store
  times = np.zeros((len(all_dataset_names), len(models), num_runs, nums_to_store))

  # Traverse through datasets
  for idx_d, dataset in enumerate(all_dataset_names):
    print('Dataset: ', dataset)
    alg = dataset[0:3]
    if alg == 'SVM':
      print('SVM')
      get_data = get_data_svm
    elif alg == 'Dec':
      print('Decision Tree')
      get_data = get_data_dtc
    elif alg == 'Log':
      print('Logistic Regression')
      get_data = get_data_lr
    elif alg == 'Dis':
      get_data = get_data_da
      print('Discriminant Analysis')
    elif alg == 'Tre':
      print('Tree Regressor')
      get_data = get_data_tr
    # Traverse through models
    for idx_m, model_str in enumerate(models):
      # Traverse through number of runs
      for run in range(num_runs):
        # Get data with different splitting seed
        X_train, X_test, y_train, y_test = get_data([dataset], split=True, random_state=random_states[run])
        len_data = X_train.shape[0] # Number of data points

        # Fit model
        model = get_model(model_str, random_states[run])
        start_time = time.time() # Start timer
        model.fit(X_train, y_train) # Train ML model
        end_time = time.time() # End timer
        duration = end_time - start_time # Get time duration for ML alg
        y_pred = model.predict(X_test)

        # Store result. Idx of dataset and Num of run
        times[idx_d][idx_m][run] = [len_data, duration]
  return times

str_ = 'a'
str_2 = 'b'

str_3 = 'a' + str_2
print(str_3)

def get_names_complexity(dat_names, num_points):
  new_dat_names = []
  idx = 0
  for dat_name in dat_names:
    num_point = str(int(num_points[idx]))
    new_dat_name = ''
    if 'bank' in dat_name:
      new_dat_name = 'Bank (Age) '

    if 'census' in dat_name:
      if 'gender' in dat_name:
        new_dat_name = 'Census (Gender) '
      else:
        new_dat_name = 'Census (Race) '

    if 'compas' in dat_name:
      if 'gender' in dat_name:
        new_dat_name = 'Compas (Gender) '
      else:
        new_dat_name = 'Compas (Race) '

    if 'credit' in dat_name:
      new_dat_name = 'Credit (Gender) '

    new_dat_names.append(new_dat_name + num_point)
    idx += 1

  return new_dat_names
# Graphs complexity of Random Forest vs XGBoost
def graph_complexity(results_times, dat_names=None):
  dat_names_np = np.array(dat_names)
  rf_x = np.squeeze(results_times[:,0])
  print("rf_x", rf_x)
  rf_y = np.squeeze(results_times[:,1])
  print("rf_y", rf_y)
  inds = np.argsort(rf_x)
  rf_x_sorted = rf_x[inds]
  rf_y_sorted = rf_y[inds]

  xgb_x = np.squeeze(results_times[:,3])
  xgb_y = np.squeeze(results_times[:,4])
  inds = np.argsort(xgb_x)
  xgb_x_sorted = xgb_x[inds]
  xgb_y_sorted = xgb_y[inds]

  bins = rf_x_sorted
  dat_names_np = dat_names_np[inds]
  dat_names = dat_names_np.tolist()

  dat_names = get_names_complexity(dat_names, rf_x_sorted)

  print('bins', bins)
  print('rf_x_sorted', rf_x_sorted)
  print('rf_y_sorted', rf_y_sorted)
  print('xgb_x_sorted', xgb_x_sorted)
  print('xgb_y_sorted', xgb_y_sorted)

  index = np.arange(len(dat_names))
  bar_width = 0.25
  fig, ax = plt.subplots()
  ax.set_xlabel('Dataset (Number of data points)')
  ax.set_ylabel('Running time (Seconds)')
  ax.set_title('DA - Number of data points vs Running time')
  rects1 = ax.bar(index, rf_y_sorted, bar_width,
                  alpha=0.4,
                  color='b',
                  label='Random Forest')
  rects2 = ax.bar(index + bar_width, xgb_y_sorted, bar_width,
                  alpha=0.5,
                  color='r',
                  label='XGBoost')
  ax.set_xticks(index + bar_width / 2)
  ax.set_xticklabels(dat_names) # Dataset Names
  for tick in ax.get_xticklabels():
    tick.set_rotation(45)
  ax.legend()

  plt.show()

"""### DTC Running Times complexity"""

models = ['rf', 'xgb']
random_states = [2001, 1500, 150, 768, 345, 876, 302, 450, 112, 2000]
rq1_times_dtc = rq1_model_time(models, random_states, [dtc_census_gender,dtc_census_race], num_runs = 10)
# Print and store results!!
complexity_dtc = get_times(rq1_times_dtc, length=2)
print('Complexity: ', complexity_dtc)
graph_complexity(complexity_dtc, [dtc_census_gender, dtc_census_race])

models = ['rf', 'xgb']
random_states = [2001, 1500, 150, 768, 345, 876, 302, 450, 112, 2000]
rq1_times_dtc = rq1_model_time(models, random_states, dtc_names, num_runs = 10)
# Print and store results!!
complexity_dtc = get_times(rq1_times_dtc, length=2)
print('Complexity: ', complexity_dtc)
graph_complexity(complexity_dtc, dtc_names)

print('Complexity: ', complexity_dtc)
graph_complexity(complexity_dtc, dtc_names)

"""### LR Running Times complexity"""

models = ['rf', 'xgb']
random_states = [2001, 1500, 150, 768, 345, 876, 302, 450, 112, 2000]
rq1_times_lr = rq1_model_time(models, random_states, lr_names, num_runs = 10)
# Print and store results!!
complexity_lr = get_times(rq1_times_lr, length=2)

print('Complexity: ', complexity_lr)
graph_complexity(complexity_lr, lr_names)

"""###  TR Times complexity"""

models = ['rf', 'xgb']
random_states = [2001, 1500, 150, 768, 345, 876, 302, 450, 112, 2000]
rq1_times_tr = rq1_model_time(models, random_states, tr_names, num_runs = 10)
# Print and store results!!
complexity_tr = get_times(rq1_times_tr, length=2)

print('Complexity: ', complexity_tr)
graph_complexity(complexity_tr, tr_names)

"""###  SVM Times complexity"""

models = ['rf', 'xgb']
random_states = [2001, 1500, 150, 768, 345, 876, 302, 450, 112, 2000]
rq1_times_svm = rq1_model_time(models, random_states, svm_names, num_runs = 10)
# Print and store results!!
complexity_svm = get_times(rq1_times_svm, length=2)

print('Complexity: ', complexity_svm)
graph_complexity(complexity_svm, svm_names)

"""###  DA Times complexity"""

models = ['rf', 'xgb']
random_states = [2001, 1500, 150, 768, 345, 876, 302, 450, 112, 2000]
rq1_times_da = rq1_model_time(models, random_states, da_names, num_runs = 10)
# Print and store results!!
complexity_da = get_times(rq1_times_da, length=2)

print('Complexity: ', complexity_da)
graph_complexity(complexity_da, da_names)

"""### Finish"""



models = ['rf', 'xgb']
random_states = [2001, 1500, 150, 768, 345, 876, 302, 450, 112, 2000]
results_rq1_times_2 = rq1_model_time(models, random_states, da_names, num_runs = 10)
# Print and store results!!
complexity_2 = get_times(results_rq1_times_2, length=2)
print('Complexity: ', complexity_2)

a = np.array([[4.45200000e+03, 1.37800000e+00, 3.46782431e-01, 4.45200000e+03,
  1.36000000e-01, 1.77606372e-02],
 [1.85700000e+03, 3.85000000e-01, 5.52980370e-02, 1.85700000e+03,
  6.90000000e-02, 7.12102811e-03],
 [2.02990000e+04, 3.55000000e+00, 9.38177001e-01, 2.02990000e+04,
  1.45000000e-01, 8.48995189e-02],
 [2.03780000e+04, 1.47300000e+00, 2.47514668e-01, 2.03780000e+04,
  1.92000000e-01, 2.38347983e-01],
 [4.08190000e+04, 4.45500000e+00, 4.28674365e-01, 4.08190000e+04,
  8.93000000e-01, 8.58688018e-01],
 [1.66700000e+03, 2.14000000e-01, 5.98919818e-03, 1.66700000e+03,
  2.38000000e-01, 2.85769717e-01]])

def graph_complexity(results_times):

  rf_x = np.squeeze(results_times[:,0])
  print("rf_x", rf_x)
  rf_y = np.squeeze(results_times[:,1])
  print("rf_y", rf_y)
  inds = np.argsort(rf_x)
  rf_x_sorted = rf_x[inds]
  rf_y_sorted = rf_y[inds]

  xgb_x = np.squeeze(results_times[:,3])
  xgb_y = np.squeeze(results_times[:,4])
  inds = np.argsort(xgb_x)
  xgb_x_sorted = xgb_x[inds]
  xgb_y_sorted = xgb_y[inds]

  plt.xlabel("Number of data points")
  plt.ylabel("Time (s)")
  plt.plot(rf_x_sorted, rf_y_sorted, label = "Random Forest")
  plt.plot(xgb_x_sorted, xgb_y_sorted, label = "XGBoost")
  plt.legend()
  plt.show()

def graph_complexity(results_times, dat_names=None):
  rf_x = np.squeeze(results_times[:,0])
  print("rf_x", rf_x)
  rf_y = np.squeeze(results_times[:,1])
  print("rf_y", rf_y)
  inds = np.argsort(rf_x)
  rf_x_sorted = rf_x[inds]
  rf_y_sorted = rf_y[inds]

  xgb_x = np.squeeze(results_times[:,3])
  xgb_y = np.squeeze(results_times[:,4])
  inds = np.argsort(xgb_x)
  xgb_x_sorted = xgb_x[inds]
  xgb_y_sorted = xgb_y[inds]

  bins = rf_x_sorted

  print('bins', bins)
  print('rf_x_sorted', rf_x_sorted)
  print('rf_y_sorted', rf_y_sorted)
  print('xgb_x_sorted', xgb_x_sorted)
  print('xgb_y_sorted', xgb_y_sorted)

  index = np.arange(6)
  bar_width = 0.25
  fig, ax = plt.subplots()
  ax.set_xlabel('Number of data')
  ax.set_ylabel('Running time')
  ax.set_title('Number of data points vs running time')
  rects1 = ax.bar(index, rf_y_sorted, bar_width,
                  alpha=0.4,
                  color='b',
                  label='Random Forest')
  rects2 = ax.bar(index + bar_width, xgb_y_sorted, bar_width,
                  alpha=0.5,
                  color='r',
                  label='XGBoost')
  ax.set_xticks(index + bar_width / 2)
  ax.set_xticklabels(["D1", "D2", "D3", "D4", "D5", "D6"])
  ax.legend()

  plt.show()

graph_complexity_3(a)



"""# AOD and EOD comparison results

## TPR results
"""

models = ['rf']
random_states = [2001, 1500, 150, 768, 345, 876, 302, 450, 112, 2000]
results_rq1_model_tpr = rq1_model(models, random_states, dtc_names, y_col = 'TPR', num_runs = 10)
# Print and store results!!
results = get_results(results_rq1_model_tpr, length=1)
print('Results: ', results)

"""Testing all 30 datasets with a different notion of fairness."""

models = ['rf']
random_states = [2001, 1500, 150, 768, 345, 876, 302, 450, 112, 2000]
results_rq1_model_tpr = rq1_model(models, random_states, all_dataset_names, y_col='TPR', num_runs=10, baseline=True)
# Print and store results!!
results = get_results_baseline(results_rq1_model_tpr, length=1)
print('Results: ', results)

print(results_rq1_model_tpr.shape)
a = results_rq1_model_tpr.squeeze()
print(a.shape)

results = get_results_baseline(a)
print('Results: ', results)

models = ['rf']
random_states = [2001, 1500, 150, 768, 345, 876, 302, 450, 112, 2000]
results_1 = rq1_model(models, random_states, all_dataset_names, y_col='TPR', num_runs=10)
# Print and store results!!
results = get_results(results_1,length=1)
print('Results: ', results)

# RQ1 Baseline
def rq1_baselines(random_states, all_dataset_names=all_dataset_names,y_col='AOD',num_runs=10):
  num_to_store = 3
  # num datasets x num models x num runs X num values to store
  results = np.zeros((len(all_dataset_names), num_runs, num_to_store))

  # Traverse through datasets
  for idx_d, dataset in enumerate(all_dataset_names):
    print('Dataset: ', dataset)
    alg = dataset[0:3]
    if alg == 'SVM':
      print('SVM')
      get_data = get_data_svm
    elif alg == 'Dec':
      print('Decision Tree')
      get_data = get_data_dtc
    elif alg == 'Log':
      print('Logistic Regression')
      get_data = get_data_lr
    elif alg == 'Dis':
      get_data = get_data_da
      print('Discriminant Analysis')
    elif alg == 'Tre':
      print('Tree Regressor')
      get_data = get_data_tr

    # Traverse through number of runs
    for run in range(num_runs):
      # Get data with different splitting seed
      X_train, X_test, y_train, y_test = get_data([dataset], split=True, random_state=random_states[run],y_col=y_col)
      print('X_train.shape: ', X_train.shape)
      print('y_train.shape: ', y_train.shape)
      print('X_test.shape: ', X_test.shape)
      print('y_test.shape: ', y_test.shape)

      # Get loss for the baseline model
      baseline_preds, avg = baseline_model(y_train, y_test.shape)
      mse_b = mean_squared_error(baseline_preds, y_test)
      rmse_b, rel_rmse_b = errors(mse_b,avg)
      r_2_b = r2_score(y_true=y_test,y_pred=baseline_preds)

      result = [rel_rmse_b, rmse_b, r_2_b]
      # Store result. Idx of dataset and Num of run
      results[idx_d][run] = result
      print(
            'Rel RMSE B.: '+str(result[0])+
            'RMSE B: '+str(result[1])+
            ', R^2 B: '+str(result[2])
            )
      print('**********************************************')
  return results

# Averages from matrix
def get_baselines(results_multiple_runs):
  num_store_values = 3 # 3 averages and 3 stdvs
  # num datasets X num values to store
  results = np.zeros((results_multiple_runs.shape[0], num_store_values * 2))
  avgs = np.average(results_multiple_runs, axis=1) # Get averages of result matrix
  stds = np.std(results_multiple_runs, axis=1) # Get standard deviations of result matrix
  print('avgs', avgs)
  print('stds', stds)
  print('avgs.shape', avgs.shape)
  print('stds.shape', stds.shape)
  # Traverse datasets
  for idx_d in range(results_multiple_runs.shape[0]):
    str_values = ''
    result_values = []

    # Averages
    rel_rmse_avg = round(avgs[idx_d][0], 3)
    rmse_avg = round(avgs[idx_d][1], 3)
    r_2_avg = round(avgs[idx_d][2], 3)
    # Standard Deviations
    rel_rmse_std = stds[idx_d][0]
    rmse_std = stds[idx_d][1]
    r_2_std = stds[idx_d][2]

    # Print values
    str_values += '& %.3f (%.3f) & %.3f (%.3f) & %.3f (%.3f) ' % (rel_rmse_avg, rel_rmse_std, rmse_avg, rmse_std, r_2_avg, r_2_std)
    # Store values
    result_values.extend([rel_rmse_avg, rel_rmse_std, rmse_avg, rmse_std, r_2_avg, r_2_std])

    results[idx_d] = result_values
    print('Complete: ', str_values)
  return results

random_states = [2001, 1500, 150, 768, 345, 876, 302, 450, 112, 2000]
baselines = rq1_baselines(random_states,all_dataset_names,y_col='TPR')
print('baselines.shape', baselines.shape)
results_baselines = get_baselines(baselines)

"""## FPR Results"""

models = ['rf']
random_states = [2001, 1500, 150, 768, 345, 876, 302, 450, 112, 2000]
results_rq1_model_fpr = rq1_model(models, random_states, dtc_names, y_col = 'FPR', num_runs = 10)
# Print and store results!!
results = get_results(results_rq1_model_fpr, length=1)
print('Results: ', results)

"""## Normal AOD results"""

models = ['rf']
random_states = [2001, 1500, 150, 768, 345, 876, 302, 450, 112, 2000]
results_rq1_model_aod = rq1_model(models, random_states, dtc_names, num_runs = 10)
# Print and store results!!
results = get_results(results_rq1_model_aod, length=1)
print('Results: ', results)

"""# NEW CENSUS

## Single datasets

Trains and predicts on a single dataset.
"""

lr_census_names = [
    lr_census_2014_sex, lr_census_2015_sex,
    lr_census_2014_race, lr_census_2015_race
]

dtc_census_names = [
    dtc_census_2014_sex, dtc_census_2015_sex,
    dtc_census_2014_race, dtc_census_2015_race
]

svm_census_names = [
    svm_census_2014_sex, svm_census_2015_sex,
    svm_census_2014_race, svm_census_2015_race
]

tr_census_names = [
    tr_census_2014_sex, tr_census_2015_sex,
    tr_census_2014_race, tr_census_2015_race
]

da_census_names = [
    da_census_2014_sex, da_census_2015_sex,
    da_census_2014_race, da_census_2015_race
]

# Decision Tree Classifier Census
models = ['svm', 'rf', 'xgb']
random_states = [2001, 1500, 150, 768, 345, 876, 302, 450, 112, 2000]
results_rq1_dtc_c = rq1_model(models, random_states, dtc_census_names, num_runs = 10)
# Print and store results
results = get_results(results_rq1_dtc_c, length=3)
print('Results: ', results)

# Decision Tree Classifier
random_states = [2001, 1500, 150, 768, 345, 876, 302, 450, 112, 2000]
results_rq1_dtc_c_nn = rq1_nn(random_states, dtc_census_names, num_runs = 10)
# Print and store results
results = get_results_baseline(results_rq1_dtc_c_nn)
print('Results: ', results)

# Logistic Regression Census
models = ['svm', 'rf', 'xgb']
random_states = [2001, 1500, 150, 768, 345, 876, 302, 450, 112, 2000]
results_rq1_lr_c = rq1_model(models, random_states, lr_census_names, num_runs = 10)
# Print and store results
results = get_results(results_rq1_lr_c, length=3)
print('Results: ', results)

# Logistic Regression Census
models = ['svm', 'rf', 'xgb']
random_states = [2001, 1500, 150, 768, 345, 876, 302, 450, 112, 2000]
results_rq1_lr_c_nn = rq1_nn(random_states, lr_census_names, num_runs = 10)
# Print and store results
results = get_results_baseline(results_rq1_lr_c_nn)
print('Results: ', results)

# Support Vector Machine Census
models = ['svm', 'rf', 'xgb']
random_states = [2001, 1500, 150, 768, 345, 876, 302, 450, 112, 2000]
results_rq1_svm_c = rq1_model(models, random_states, svm_census_names, num_runs = 10)
# Print and store results
results = get_results(results_rq1_svm_c, length=3)
print('Results: ', results)

# Support Vector Machine
random_states = [2001, 1500, 150, 768, 345, 876, 302, 450, 112, 2000]
results_rq1_svm_c_nn = rq1_nn(random_states, svm_census_names, num_runs = 10)
# Print and store results
results = get_results_baseline(results_rq1_svm_c_nn)
print('Results: ', results)

# Tree Regressor Census
models = ['svm', 'rf', 'xgb']
random_states = [2001, 1500, 150, 768, 345, 876, 302, 450, 112, 2000]
results_rq1_tr_c = rq1_model(models, random_states, tr_census_names, num_runs = 10)
# Print and store results
results = get_results(results_rq1_tr_c, length=3)
print('Results: ', results)

# Tree Regressor
results_rq1_tr_c_nn = rq1_nn(random_states, tr_census_names, num_runs = 10)
# Print and store results
results = get_results_baseline(results_rq1_tr_c_nn)
print('Results: ', results)

# Discriminant Analysis Census
models = ['svm', 'rf', 'xgb']
random_states = [2001, 1500, 150, 768, 345, 876, 302, 450, 112, 2000]
results_rq1_da_c = rq1_model(models, random_states, da_census_names, num_runs = 10)
# Print and store results
results = get_results(results_rq1_da_c, length=3)
print('Results: ', results)

# Discriminant Analysis
results_rq1_da_c_nn = rq1_nn(random_states, da_census_names, num_runs = 10)
# Print and store results
results = get_results_baseline(results_rq1_da_c_nn)
print('Results: ', results)

"""## Single datasets 2018

Trains and predicts on a single dataset.
"""

lr_census_names_2018_s = [
    lr_census_2018_sex, lr_census_2018_race
]

dtc_census_names_2018_s = [
    dtc_census_2018_sex, dtc_census_2018_race
]

svm_census_names_2018_s = [
    svm_census_2018_sex, svm_census_2018_race
]

tr_census_names_2018_s = [
    tr_census_2018_sex, tr_census_2018_race
]

da_census_names_2018_s = [
    da_census_2018_sex, da_census_2018_race
]

# Decision Tree Classifier Census
models = ['svm', 'rf', 'xgb']
random_states = [2001, 1500, 150, 768, 345, 876, 302, 450, 112, 2000]
results_rq1_dtc_c = rq1_model(models, random_states, dtc_census_names_2018_s, num_runs = 10)
# Print and store results
results = get_results(results_rq1_dtc_c, length=3)
print('Results: ', results)

results_rq1_dtc_c_nn = rq1_nn(random_states, dtc_census_names_2018_s, num_runs = 10)
# Print and store results
results = get_results_baseline(results_rq1_dtc_c_nn)
print('Results: ', results)

# Logistic Regression Census
models = ['svm', 'rf', 'xgb']
random_states = [2001, 1500, 150, 768, 345, 876, 302, 450, 112, 2000]
results_rq1_lr_c = rq1_model(models, random_states, lr_census_names_2018_s, num_runs = 10)
# Print and store results
results = get_results(results_rq1_lr_c, length=3)
print('Results: ', results)

results_rq1_lr_c_nn = rq1_nn(random_states, lr_census_names_2018_s, num_runs = 10)
# Print and store results
results = get_results_baseline(results_rq1_lr_c_nn)
print('Results: ', results)

# Tree Regressor Census
models = ['svm', 'rf', 'xgb']
random_states = [2001, 1500, 150, 768, 345, 876, 302, 450, 112, 2000]
results_rq1_tr_c = rq1_model(models, random_states, tr_census_names_2018_s, num_runs = 10)
# Print and store results
results = get_results(results_rq1_tr_c, length=3)
print('Results: ', results)

results_rq1_tr_c_nn = rq1_nn(random_states, tr_census_names_2018_s, num_runs = 10)
# Print and store results
results = get_results_baseline(results_rq1_tr_c_nn)
print('Results: ', results)

# Support Vector Machine Census
models = ['svm', 'rf', 'xgb']
random_states = [2001, 1500, 150, 768, 345, 876, 302, 450, 112, 2000]
results_rq1_svm_c = rq1_model(models, random_states, svm_census_names_2018_s, num_runs = 10)
# Print and store results
results = get_results(results_rq1_svm_c, length=3)
print('Results: ', results)

results_rq1_svm_c_nn = rq1_nn(random_states, svm_census_names_2018_s, num_runs = 10)
# Print and store results
results = get_results_baseline(results_rq1_svm_c_nn)
print('Results: ', results)

# Discriminant Analysis Census
models = ['svm', 'rf', 'xgb']
random_states = [2001, 1500, 150, 768, 345, 876, 302, 450, 112, 2000]
results_rq1_da_c = rq1_model(models, random_states, da_census_names_2018_s, num_runs = 10)
# Print and store results
results = get_results(results_rq1_da_c, length=3)
print('Results: ', results)

results_rq1_da_c_nn = rq1_nn(random_states, da_census_names_2018_s, num_runs = 10)
# Print and store results
results = get_results_baseline(results_rq1_da_c_nn)
print('Results: ', results)

"""## Cross-experiments

Trains an algorithm in one dataset and predicts in a different dataset.
"""

lr_cross_census_training = [
    lr_census_2014_sex, lr_census_2015_sex,
    lr_census_2014_race, lr_census_2015_race
]

lr_cross_census_testing = [
    lr_census_2015_sex, lr_census_2014_sex,
    lr_census_2015_race, lr_census_2014_race
]

dtc_cross_census_training = [
    dtc_census_2014_sex, dtc_census_2015_sex,
    dtc_census_2014_race, dtc_census_2015_race
]

dtc_cross_census_testing = [
    dtc_census_2015_sex, dtc_census_2014_sex,
    dtc_census_2015_race, dtc_census_2014_race
]

svm_cross_census_training = [
    svm_census_2014_sex, svm_census_2015_sex,
    svm_census_2014_race, svm_census_2015_race
]

svm_cross_census_testing = [
    svm_census_2015_sex, svm_census_2014_sex,
    svm_census_2015_race, svm_census_2014_race
]

tr_cross_census_training = [
    tr_census_2014_sex, tr_census_2015_sex,
    tr_census_2014_race, tr_census_2015_race
]

tr_cross_census_testing = [
    tr_census_2015_sex, tr_census_2014_sex,
    tr_census_2015_race, tr_census_2014_race
]

da_cross_census_training = [
    da_census_2014_sex, da_census_2015_sex,
    da_census_2014_race, da_census_2015_race
]

da_cross_census_testing = [
    da_census_2015_sex, da_census_2014_sex,
    da_census_2015_race, da_census_2014_race
]

models = ['svm', 'rf', 'xgb']
random_states = [2001, 1500, 150, 768, 345, 876, 302, 450, 112, 2000]
results_rq2_dtc_c = rq2_model(models, random_states, dtc_cross_census_training, dtc_cross_census_testing)
# Print and store results!!
results = get_results(results_rq2_dtc_c, length=3)
print('Results: ', results)

random_states = [2001, 1500, 150, 768, 345, 876, 302, 450, 112, 2000]
results_rq2_dtc_nn = rq2_nn(random_states, dtc_cross_census_training, dtc_cross_census_testing)
# Print and store results
results_rq2_nn_1 = get_results_baseline(results_rq2_dtc_nn)
print('Results: ', results_rq2_nn_1)

models = ['svm', 'rf', 'xgb']
random_states = [2001, 1500, 150, 768, 345, 876, 302, 450, 112, 2000]
results_rq2_lr_c = rq2_model(models, random_states, lr_cross_census_training, lr_cross_census_testing)
# Print and store results!!
results = get_results(results_rq2_lr_c, length=3)
print('Results: ', results)

random_states = [2001, 1500, 150, 768, 345, 876, 302, 450, 112, 2000]
results_rq2_lr_nn = rq2_nn(random_states, lr_cross_census_training, lr_cross_census_testing)
# Print and store results
results_rq2_nn_1 = get_results_baseline(results_rq2_lr_nn)
print('Results: ', results_rq2_nn_1)

models = ['svm', 'rf', 'xgb']
random_states = [2001, 1500, 150, 768, 345, 876, 302, 450, 112, 2000]
results_rq2_tr_c = rq2_model(models, random_states, tr_cross_census_training, tr_cross_census_testing)
# Print and store results!!
results = get_results(results_rq2_tr_c, length=3)
print('Results: ', results)

random_states = [2001, 1500, 150, 768, 345, 876, 302, 450, 112, 2000]
results_rq2_tr_nn = rq2_nn(random_states, tr_cross_census_training, tr_cross_census_testing)
# Print and store results
results_rq2_nn_1 = get_results_baseline(results_rq2_tr_nn)
print('Results: ', results_rq2_nn_1)

models = ['svm', 'rf', 'xgb']
random_states = [2001, 1500, 150, 768, 345, 876, 302, 450, 112, 2000]
results_rq2_svm_c = rq2_model(models, random_states, svm_cross_census_training, svm_cross_census_testing)
# Print and store results!!
results = get_results(results_rq2_svm_c, length=3)
print('Results: ', results)

random_states = [2001, 1500, 150, 768, 345, 876, 302, 450, 112, 2000]
results_rq2_svm_nn = rq2_nn(random_states, svm_cross_census_training, svm_cross_census_testing)
# Print and store results
results_rq2_nn_1 = get_results_baseline(results_rq2_svm_nn)
print('Results: ', results_rq2_nn_1)

models = ['svm', 'rf', 'xgb']
random_states = [2001, 1500, 150, 768, 345, 876, 302, 450, 112, 2000]
results_rq2_da_c = rq2_model(models, random_states, da_cross_census_training, da_cross_census_testing)
# Print and store results!!
results = get_results(results_rq2_da_c, length=3)
print('Results: ', results)

random_states = [2001, 1500, 150, 768, 345, 876, 302, 450, 112, 2000]
results_rq2_da_nn = rq2_nn(random_states, da_cross_census_training, da_cross_census_testing)
# Print and store results
results_rq2_nn_1 = get_results_baseline(results_rq2_da_nn)
print('Results: ', results_rq2_nn_1)

"""## 2018 Cross-experiment

"""

lr_cross_census_training_2018 = [
    lr_census_2014_sex, lr_census_2015_sex,
    lr_census_2014_race, lr_census_2015_race
]

lr_cross_census_testing_2018 = [
    lr_census_2018_sex, lr_census_2018_sex,
    lr_census_2018_race, lr_census_2018_race
]

dtc_cross_census_training_2018 = [
    dtc_census_2014_sex, dtc_census_2015_sex,
    dtc_census_2014_race, dtc_census_2015_race
]

dtc_cross_census_testing_2018 = [
    dtc_census_2018_sex, dtc_census_2018_sex,
    dtc_census_2018_race, dtc_census_2018_race
]

svm_cross_census_training_2018 = [
    svm_census_2014_sex, svm_census_2015_sex,
    svm_census_2014_race, svm_census_2015_race
]

svm_cross_census_testing_2018 = [
    svm_census_2018_sex, svm_census_2018_sex,
    svm_census_2018_race, svm_census_2018_race
]

tr_cross_census_training_2018 = [
    tr_census_2014_sex, tr_census_2015_sex,
    tr_census_2014_race, tr_census_2015_race
]

tr_cross_census_testing_2018 = [
    tr_census_2018_sex, tr_census_2018_sex,
    tr_census_2018_race, tr_census_2018_race
]

da_cross_census_training_2018 = [
    da_census_2014_sex, da_census_2015_sex,
    da_census_2014_race, da_census_2015_race
]

da_cross_census_testing_2018 = [
    da_census_2018_sex, da_census_2018_sex,
    da_census_2018_race, da_census_2018_race
]

models = ['svm', 'rf', 'xgb']
random_states = [2001, 1500, 150, 768, 345, 876, 302, 450, 112, 2000]
results_rq2_dtc_c = rq2_model(models, random_states, dtc_cross_census_training_2018, dtc_cross_census_testing_2018)
# Print and store results!!
results = get_results(results_rq2_dtc_c, length=3)
print('Results: ', results)

random_states = [2001, 1500, 150, 768, 345, 876, 302, 450, 112, 2000]
results_rq2_dtc_nn = rq2_nn(random_states, dtc_cross_census_training_2018, dtc_cross_census_testing_2018)
# Print and store results
results_rq2_nn_1 = get_results_baseline(results_rq2_dtc_nn)
print('Results: ', results_rq2_nn_1)

models = ['svm', 'rf', 'xgb']
random_states = [2001, 1500, 150, 768, 345, 876, 302, 450, 112, 2000]
results_rq2_lr_c = rq2_model(models, random_states, lr_cross_census_training_2018, lr_cross_census_testing_2018)
# Print and store results!!
results = get_results(results_rq2_lr_c, length=3)
print('Results: ', results)

random_states = [2001, 1500, 150, 768, 345, 876, 302, 450, 112, 2000]
results_rq2_lr_nn = rq2_nn(random_states, lr_cross_census_training_2018, lr_cross_census_testing_2018)
# Print and store results
results_rq2_nn_1 = get_results_baseline(results_rq2_lr_nn)
print('Results: ', results_rq2_nn_1)

models = ['svm', 'rf', 'xgb']
random_states = [2001, 1500, 150, 768, 345, 876, 302, 450, 112, 2000]
results_rq2_tr_c = rq2_model(models, random_states, tr_cross_census_training_2018, tr_cross_census_testing_2018)
# Print and store results!!
results = get_results(results_rq2_tr_c, length=3)
print('Results: ', results)

random_states = [2001, 1500, 150, 768, 345, 876, 302, 450, 112, 2000]
results_rq2_tr_nn = rq2_nn(random_states, tr_cross_census_training_2018, tr_cross_census_testing_2018)
# Print and store results
results_rq2_nn_1 = get_results_baseline(results_rq2_tr_nn)
print('Results: ', results_rq2_nn_1)

models = ['svm', 'rf', 'xgb']
random_states = [2001, 1500, 150, 768, 345, 876, 302, 450, 112, 2000]
results_rq2_svm_c = rq2_model(models, random_states, svm_cross_census_training_2018, svm_cross_census_testing_2018)
# Print and store results!!
results = get_results(results_rq2_svm_c, length=3)
print('Results: ', results)

random_states = [2001, 1500, 150, 768, 345, 876, 302, 450, 112, 2000]
results_rq2_svm_nn = rq2_nn(random_states, svm_cross_census_training_2018, svm_cross_census_testing_2018)
# Print and store results
results_rq2_nn_1 = get_results_baseline(results_rq2_svm_nn)
print('Results: ', results_rq2_nn_1)

models = ['svm', 'rf', 'xgb']
random_states = [2001, 1500, 150, 768, 345, 876, 302, 450, 112, 2000]
results_rq2_da_c = rq2_model(models, random_states, da_cross_census_training_2018, da_cross_census_testing_2018)
# Print and store results!!
results = get_results(results_rq2_da_c, length=3)
print('Results: ', results)

random_states = [2001, 1500, 150, 768, 345, 876, 302, 450, 112, 2000]
results_rq2_da_nn = rq2_nn(random_states, da_cross_census_training_2018, da_cross_census_testing_2018)
# Print and store results
results_rq2_nn_1 = get_results_baseline(results_rq2_da_nn)
print('Results: ', results_rq2_nn_1)

# Good
dtc_cross_census_training_2 =[
    [dtc_census_2014_sex, dtc_census_2015_sex],
    [dtc_census_2014_race, dtc_census_2015_race]
]

dtc_cross_census_testing_2 = [
    dtc_census_2018_sex,
    dtc_census_2018_race
]

lr_cross_census_training_2 =[
    [lr_census_2014_sex, lr_census_2015_sex],
    [lr_census_2014_race, lr_census_2015_race]
]

lr_cross_census_testing_2 = [
    lr_census_2018_sex,
    lr_census_2018_race
]

tr_cross_census_training_2 =[
    [tr_census_2014_sex, tr_census_2015_sex],
    [tr_census_2014_race, tr_census_2015_race]
]

tr_cross_census_testing_2 = [
    tr_census_2018_sex,
    tr_census_2018_race
]

svm_cross_census_training_2 =[
    [svm_census_2014_sex, svm_census_2015_sex],
    [svm_census_2014_race, svm_census_2015_race]
]

svm_cross_census_testing_2 = [
    svm_census_2018_sex,
    svm_census_2018_race
]

da_cross_census_training_2 =[
    [da_census_2014_sex, da_census_2015_sex],
    [da_census_2014_race, da_census_2015_race]
]

da_cross_census_testing_2 = [
    da_census_2018_sex,
    da_census_2018_race
]

models = ['svm', 'rf', 'xgb']
random_states = [2001, 1500, 150, 768, 345, 876, 302, 450, 112, 2000]
results_rq2_dtc_c = rq2_model(models, random_states, dtc_cross_census_training_2, dtc_cross_census_testing_2)
# Print and store results!!
results = get_results(results_rq2_dtc_c, length=3)
print('Results: ', results)

models = ['svm', 'rf', 'xgb']
random_states = [2001, 1500, 150, 768, 345, 876, 302, 450, 112, 2000]
results_rq2_lr_c = rq2_model(models, random_states,lr_cross_census_training_2, lr_cross_census_testing_2)
# Print and store results!!
results = get_results(results_rq2_lr_c, length=3)
print('Results: ', results)

models = ['svm', 'rf', 'xgb']
random_states = [2001, 1500, 150, 768, 345, 876, 302, 450, 112, 2000]
results_rq2_tr_c = rq2_model(models, random_states, tr_cross_census_training_2, tr_cross_census_testing_2)
# Print and store results!!
results = get_results(results_rq2_tr_c, length=3)
print('Results: ', results)

models = ['svm', 'rf', 'xgb']
random_states = [2001, 1500, 150, 768, 345, 876, 302, 450, 112, 2000]
results_rq2_svm_c = rq2_model(models, random_states, svm_cross_census_training_2, svm_cross_census_testing_2)
# Print and store results!!
results = get_results(results_rq2_svm_c, length=3)
print('Results: ', results)

models = ['svm', 'rf', 'xgb']
random_states = [2001, 1500, 150, 768, 345, 876, 302, 450, 112, 2000]
results_rq2_da_c = rq2_model(models, random_states, da_cross_census_training_2, da_cross_census_testing_2)
# Print and store results!!
results = get_results(results_rq2_da_c, length=3)
print('Results: ', results)

"""## State comparison"""

state_cross_census_training = [
    lr_census_2014_sex, lr_census_2015_sex,
    lr_census_2014_race, lr_census_2015_race
]

state_cross_census_testing = [
    lr_census_2015_sex, lr_census_2014_sex,
    lr_census_2015_race, lr_census_2014_race
]

models = ['svm', 'rf', 'xgb']
random_states = [2001, 1500, 150, 768, 345, 876, 302, 450, 112, 2000]
results_rq2_dtc_c = rq2_model(models, random_states, dtc_cross_census_training, dtc_cross_census_testing)
# Print and store results!!
results = get_results(results_rq2_dtc_c, length=3)
print('Results: ', results)